{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5097efe3-58c6-47cb-9cc0-cc0e9751faaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script reproduces the data generation of the perturb-cite-seq data used in the NODAGS-Flow paper.\n",
    "\"\"\"\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*The loaded checkpoint was .*\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "from bicycle.utils.data import create_loaders\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a9c8c4d-3fc3-432b-94c7-363b6cc4d629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH_ORIGINAL = Path(\"/scratch/ueltzhoe/nodags_data_original\")\n",
    "DATA_PATH_COUNTS = Path(\"/scratch/ueltzhoe/nodags_data\")\n",
    "\n",
    "DATASET = \"control\"\n",
    "\n",
    "train_loader_COUNTS = torch.load(DATA_PATH_COUNTS / f\"{DATASET}/training_data/train_loader.pth\")\n",
    "validation_loader_COUNTS = torch.load(DATA_PATH_COUNTS / f\"{DATASET}/validation_data/validation_loader.pth\")\n",
    "test_loader_COUNTS = torch.load(DATA_PATH_COUNTS / f\"{DATASET}/test_data/test_loader.pth\")\n",
    "labels_COUNTS = np.load(DATA_PATH_COUNTS / f\"{DATASET}/labels.npy\", allow_pickle=True)\n",
    "\n",
    "train_loader_ORIGINAL = torch.load(DATA_PATH_ORIGINAL / f\"{DATASET}/training_data/train_loader.pth\")\n",
    "validation_loader_ORIGINAL = torch.load(DATA_PATH_ORIGINAL / f\"{DATASET}/validation_data/validation_loader.pth\")\n",
    "test_loader_ORIGINAL = torch.load(DATA_PATH_ORIGINAL / f\"{DATASET}/test_data/test_loader.pth\")\n",
    "labels = np.load(DATA_PATH_ORIGINAL / f\"{DATASET}/labels.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d306843-7e16-4e18-9a4b-a21af5d92a61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 0.,  0.,  4.,  7.,  0.,  1.,  3.,  0.,  1.,  0.,  0.,  2.,  1.,  2.,\n",
      "         2.,  0.,  0.,  0.,  0.,  0.,  0.,  5.,  0.,  0.,  0.,  2.,  0.,  1.,\n",
      "         1.,  0.,  0.,  0.,  5.,  1.,  1.,  0.,  3.,  0.,  0., 13.,  1.,  0.,\n",
      "         0.,  3.,  2.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,  1.,  1.,  1.,  0.,\n",
      "         0.,  1.,  1.,  0.,  1.]), tensor(0), tensor(0), tensor(0.))\n"
     ]
    }
   ],
   "source": [
    "print(train_loader_COUNTS.dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76f4ddec-9132-4ad2-be62-e7f408059302",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader_COUNTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85bb7d7c-ae37-46d6-a96e-997548480212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.18314914568623816\n",
      "Index differences: tensor(0)\n",
      "Split differences: tensor(0.)\n",
      "Correlation: 0.18087700424836162\n",
      "Index differences: tensor(0)\n",
      "Split differences: tensor(0.)\n",
      "Correlation: 0.18352763470841416\n",
      "Index differences: tensor(0)\n",
      "Split differences: tensor(0.)\n",
      "Correlation: 0.18660117469095724\n",
      "Index differences: tensor(0)\n",
      "Split differences: tensor(0.)\n",
      "Correlation: 0.18537585749530025\n",
      "Index differences: tensor(0)\n",
      "Split differences: tensor(0.)\n",
      "Correlation: 0.1875636079713089\n",
      "Index differences: tensor(0)\n",
      "Split differences: tensor(0.)\n",
      "Correlation: 0.1840679694788356\n",
      "Index differences: tensor(0)\n",
      "Split differences: tensor(0.)\n",
      "Correlation: 0.1882463788759881\n",
      "Index differences: tensor(0)\n",
      "Split differences: tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(0)\n",
    "\n",
    "all_samples_counts = list()\n",
    "all_regimes_counts = list()\n",
    "all_idx_counts = list()\n",
    "all_splits_counts = list()\n",
    "for i in range(len(train_loader_COUNTS)):\n",
    "    samples_counts, regimes_counts, idx_counts, splits_counts = next(iter(train_loader_COUNTS))\n",
    "    all_samples_counts.append(samples_counts)\n",
    "    all_regimes_counts.append(regimes_counts)\n",
    "    all_idx_counts.append(idx_counts)\n",
    "    all_splits_counts.append(splits_counts)\n",
    "    \n",
    "pl.seed_everything(0)\n",
    "\n",
    "all_samples_original = list()\n",
    "all_regimes_original = list()\n",
    "all_idx_original = list()\n",
    "all_splits_original = list()\n",
    "for i in range(len(train_loader_ORIGINAL)):\n",
    "    samples_original, regimes_original, idx_original, splits_original = next(iter(train_loader_ORIGINAL))\n",
    "    all_samples_original.append(samples_original)\n",
    "    all_regimes_original.append(regimes_original)\n",
    "    all_idx_original.append(idx_original)\n",
    "    all_splits_original.append(splits_original)\n",
    "    \n",
    "for counts, original, idx_counts, idx_original, splits_counts, splits_original in zip(\n",
    "    all_samples_counts, all_samples_original, all_idx_counts, all_idx_original, all_splits_counts, all_splits_original):\n",
    "    \n",
    "    counts = counts.cpu().numpy().reshape((-1,))\n",
    "    original = original.cpu().numpy().reshape((-1,))\n",
    "\n",
    "    print('Correlation:', np.corrcoef(counts,original)[0,1])\n",
    "\n",
    "    print('Index differences:', (idx_counts - idx_original).abs().sum() )\n",
    "    \n",
    "    print('Split differences:', (splits_counts - splits_original).abs().sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e6b746-221a-4084-acab-f0ed654318c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-3.10-local",
   "language": "python",
   "name": "py-3.10-local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
