{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b1cfb40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_490721/280359223.py:15: DeprecationWarning: Please import `ttest_ind` from the `scipy.stats` namespace; the `scipy.stats.stats` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  from scipy.stats.stats import ttest_ind, ttest_rel\n",
      "/tmp/ipykernel_490721/280359223.py:15: DeprecationWarning: Please import `ttest_rel` from the `scipy.stats` namespace; the `scipy.stats.stats` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  from scipy.stats.stats import ttest_ind, ttest_rel\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.metrics import precision_recall_curve, roc_curve, auc, average_precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from bicycle.model import BICYCLE\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "#from bicycle.utils.mask_utils import get_sparsity, above_threshold, string_to_list\n",
    "import json\n",
    "from glob import glob\n",
    "#from scipy.special import expit\n",
    "import scanpy as sc\n",
    "import re\n",
    "from bicycle.utils.data import create_loaders\n",
    "from scipy.stats.stats import ttest_ind, ttest_rel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a8207475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_scientific(df, param_of_interest, ax, colors = ['skyblue', 'salmon'], bar_width = 0.35, annotate = True, a = 0.05):\n",
    "    metrics = df.columns.drop(param_of_interest)\n",
    "    x = np.arange(len(metrics))\n",
    "    \n",
    "    unique_df = np.unique(df[param_of_interest])\n",
    "    p_dict = {}\n",
    "    for i, metric in enumerate(metrics):\n",
    "        vals = {}\n",
    "        means = {}\n",
    "        stds = {}\n",
    "        x_pos = {}\n",
    "        for n, v in enumerate(unique_df):\n",
    "            values = df[df[param_of_interest] == v][metric].astype(float)\n",
    "            vals[v] = values\n",
    "            means[v], stds[v] = values.mean(), values.std()\n",
    "            # Bar positions\n",
    "            x_pos[v] = x[i] + bar_width * n + i*(bar_width*len(unique_df))\n",
    "            # Plot bars\n",
    "            if annotate:\n",
    "                ax.text(x_pos[v], 0, np.round(means[v], 3), ha = \"center\")\n",
    "            ax.bar(x_pos[v], means[v], yerr=stds[v], capsize=bar_width*3, width=bar_width, color=colors[n], label=v if i == 0 else \"\")\n",
    "        \n",
    "        # Significance test\n",
    "        tested = []\n",
    "        for p1, v1 in vals.items():\n",
    "            for p2, v2 in vals.items():\n",
    "                if p1==p2 or (p1,p2) in tested or (p2,p1) in tested:\n",
    "                    continue\n",
    "                else:\n",
    "                    tested.append((p1,p2))\n",
    "                print((p1, p2))\n",
    "        \n",
    "                _, p_val = ttest_ind(v1, v2, equal_var=False)\n",
    "\n",
    "                # Define significance level\n",
    "                if  p_val < a:\n",
    "                    sig = \"*\"\n",
    "                    sig += \"\".join([\"*\" for n in np.logspace(-2, -5, num=4) if p_val<n])\n",
    "                    p_dict[f\"{metric}: {p1}, {p2}\"] = p_val\n",
    "\n",
    "                else:\n",
    "                    sig = False\n",
    "\n",
    "                if sig:\n",
    "                    # Draw annotation line\n",
    "                    y_max = ax.get_yticks()[-1]*0.9\n",
    "                    ax.plot(np.repeat([x_pos[p1], x_pos[p2]], 2), [y_max*0.99,y_max, y_max, y_max*0.99], color='black', linewidth=1)\n",
    "                    ax.text((x_pos[p1] + x_pos[p2])/2, y_max + 0.01, sig, ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "    # Final layout\n",
    "    print(f\"Significant p-values: {p_dict}\")\n",
    "    ax.set_xticks(x*(bar_width*(len(unique_df)+1))+bar_width/2*len(unique_df), [m.replace(\"_\", \"\\n\").capitalize() for m in metrics])\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    return p_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9a356c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, key, models_path, **kwargs):\n",
    "    samples = torch.tensor(np.load(models_path/key/\"synthetic_data\"/\"check_sim_samples.npy\"))\n",
    "    sim_regime = torch.tensor(np.load(models_path/key/\"synthetic_data\"/\"check_sim_regimes.npy\"))\n",
    "    train_gene_ko = model.train_gene_ko\n",
    "    test_gene_ko = model.test_gene_ko\n",
    "    if len(test_gene_ko)>20:\n",
    "        overhang = len(test_gene_ko)-20\n",
    "        print(f\"More than 20 test_genes! Removing last {overhang} contexts.\")\n",
    "        regimes = sim_regime.unique()[-overhang:]\n",
    "        for regime in regimes:\n",
    "            mask = sim_regime != regime\n",
    "            samples = samples[mask]\n",
    "            sim_regime = sim_regime[mask]\n",
    "        test_gene_ko = test_gene_ko[:-overhang]\n",
    "    train_loader, validation_loader, test_loader = create_loaders(\n",
    "        samples=samples, # test_loader is None\n",
    "        sim_regime=sim_regime,\n",
    "        validation_size=kwargs.get(\"validation_size\", 0.),\n",
    "        batch_size=kwargs.get(\"batch_size\", 100000),\n",
    "        SEED= kwargs.get(\"SEED\", 1),\n",
    "        train_gene_ko=train_gene_ko,\n",
    "        test_gene_ko=test_gene_ko,\n",
    "        persistent_workers=False,\n",
    "        covariates=None,\n",
    "        num_workers= 1,\n",
    "    )\n",
    "    return model.evaluate(test_loader.dataset, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9a4724c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg1(params, param_of_interest):\n",
    "    params = params.sort_index()\n",
    "    params[\"config\"] = [\"Vanilla\", \"Bayes prior\", \"Binary Prior\"]\n",
    "    param_of_interest = \"config\"\n",
    "    return params, param_of_interest\n",
    "def agg2(params, param_of_interest):\n",
    "    params = params.sort_index()\n",
    "    return params, param_of_interest\n",
    "def agg3(params, param_of_interest):\n",
    "    params = params.sort_index()\n",
    "    params[\"Config\"] = [\"Vanilla\\n5 TFs\", \"Masking\\n5 TFs\", \"Vanilla\\n10 TFs\", \"Masking\\n10 TFs\"]\n",
    "    params = params.iloc[[0,2,1,3]]\n",
    "    param_of_interest = \"Config\"\n",
    "    return params, param_of_interest\n",
    "def agg4(params, param_of_interest):\n",
    "    params = params.sort_values(param_of_interest)\n",
    "    params[\"Config\"] = [\"Vanilla\\n400\", \"Masking\\n400\", \"Masking\\n200\", \"Masking\\n100\", \"Vanilla\\n200\", \"Vanilla\\n100\"]\n",
    "    param_of_interest = \"Config\"\n",
    "    params = params.sort_values(\"Config\")\n",
    "    return params, param_of_interest\n",
    "def agg5(params, param_of_interest):\n",
    "    params = params.sort_values(param_of_interest)\n",
    "    if len(params)>4:\n",
    "        params[\"pert. factor\"] = (1/10**np.arange(4, -1,-1)).astype(str)\n",
    "    else:\n",
    "        params[\"pert. factor\"] = 1/np.arange(4, 0,-1)\n",
    "\n",
    "    param_of_interest = \"pert. factor\"\n",
    "    params=params.sort_values(param_of_interest)\n",
    "    return params, param_of_interest\n",
    "def agg6(params, param_of_interest):\n",
    "    params[param_of_interest] = params[param_of_interest].astype(float)\n",
    "    params = params.sort_values(param_of_interest)\n",
    "    return params, param_of_interest\n",
    "def agg7(params, param_of_interest):\n",
    "    params = params.sort_index()\n",
    "    params[\"config\"] = [\"Vanilla_old\",\"Vanilla\", \"Bayes prior\", \"Binary Prior\"]\n",
    "    param_of_interest = \"config\"\n",
    "    return params, param_of_interest\n",
    "def agg8(params, param_of_interest):\n",
    "    params = params.sort_index()\n",
    "    params[\"config\"] = params[\"data_id\"]+params[\"masking_mode\"]\n",
    "    param_of_interest = \"config\"\n",
    "    return params, param_of_interest\n",
    "def agg_paper(params, param_of_interest):\n",
    "    params = params.sort_index()\n",
    "    params[\"config\"] = params[param_of_interest] + \" + \" + params[\"masking_mode\"]\n",
    "    param_of_interest = \"config\"\n",
    "    return params, param_of_interest\n",
    "def agg(params, param_of_interest):\n",
    "    params = params.sort_index()\n",
    "    if type(param_of_interest) is dict:\n",
    "        params[\"config\"] = params[param_of_interest[\"0\"]] + \" + \" + params[param_of_interest[\"1\"]]\n",
    "        index = params.isna()[\"config\"]\n",
    "        params.loc[index,\"config\"] = params.loc[index, param_of_interest[\"0\"]]\n",
    "        param_of_interest = \"config\"\n",
    "        params.sort_values(param_of_interest)\n",
    "    return params, param_of_interest\n",
    "\n",
    "functions = {\n",
    "    \"agg1\":agg1,\n",
    "    \"agg2\":agg2,\n",
    "    \"agg3\":agg3,\n",
    "    \"agg4\":agg4,\n",
    "    \"agg5\":agg5,\n",
    "    \"agg6\":agg6,\n",
    "    \"agg7\":agg7,\n",
    "    \"agg8\":agg8,\n",
    "    \"agg_paper\":agg_paper,\n",
    "    \"agg\": agg,\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8fa63521",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e552a1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible experiments: ['bin', 'noisefactor5', 'init', 'TFs', 'npert', 'spert', 'original', 'scalefactor5', 'erdos', 'bicycle_data', 'scalefactor_b', 'eigenvalues_scm', 'scalefactor_papersem1', 'scalefactor_papersem2', 'paper', 'PapervsMaskSEM2', 'paperSEM2', 'paper_nolat', 'paper_nolatSEM2', 'latentsvsnolatentsSEM2', 'onlybicycle_data']\n"
     ]
    }
   ],
   "source": [
    "# get environment\n",
    "with open(\"./data/experiment_configs.json\", \"r\") as rf:\n",
    "    config_sets = json.load(rf)\n",
    "print(f\"Possible experiments: {list(config_sets.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "951c2a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: onlybicycle_data\n",
      "run_043\n",
      "run_045\n",
      "run_042\n",
      "run_044\n"
     ]
    }
   ],
   "source": [
    "experiment = \"onlybicycle_data\"\n",
    "config_set = config_sets[experiment]\n",
    "include = config_set[\"include\"]\n",
    "id_len = config_set[\"id_len\"]\n",
    "prefix = config_set[\"prefix\"]\n",
    "param_of_interest = config_set[\"param_of_interest\"]\n",
    "agg = config_set[\"function\"]\n",
    "\n",
    "#include = np.array([98,99])\n",
    "#id_len = 3\n",
    "#prefix = \"run_\"\n",
    "#experiment = None\n",
    "#param_of_interest = \"data_source\"\n",
    "#agg = None\n",
    "print(f\"Experiment: {experiment}\")\n",
    "models_path = Path(\"/data/toulouse/bicycle/notebooks/experiments/masking/data/model_runs/models/\")\n",
    "plot_path = Path(\"/data/toulouse/bicycle/notebooks/experiments/masking/data/model_runs/plots\")\n",
    "data_path = Path(\"./data/\")\n",
    "columns = [\n",
    "    \"model_lr\",\n",
    "    \"model_n_genes\",\n",
    "    \"model_n_samples\",\n",
    "    \"pretraining_time\",\n",
    "    \"training_time\",\n",
    "    \"compile\",\n",
    "    \"trad_loading\",\n",
    "    \"scale_mask\",\n",
    "    \"grn_noise_p\",\n",
    "    \"n_epochs\",\n",
    "    \"use_hard_mask\",\n",
    "    \"masking_mode\",\n",
    "    \"bin_prior\",\n",
    "    \"data_id\",\n",
    "    \"data_source\",\n",
    "    \"nll\",\n",
    "    \"max_f1\",\n",
    "    \"average_precision\",\n",
    "    \"auroc\",\n",
    "    \"prior_average_precision\",\n",
    "    \"prior_auroc\",\n",
    "    \"model_use_latents\"\n",
    "    ]\n",
    "if not param_of_interest in columns and not type(param_of_interest) is dict:\n",
    "    columns.append(param_of_interest)\n",
    "    print(f\"Adding {param_of_interest}\")\n",
    "elif isinstance(param_of_interest, dict):\n",
    "     for item in param_of_interest.values():\n",
    "        if item not in columns:\n",
    "            columns.append(item)\n",
    "params = pd.DataFrame(columns=columns)\n",
    "for dir in plot_path.iterdir():\n",
    "    if dir.name[:-id_len] != prefix:\n",
    "         continue\n",
    "    if int(dir.name[-id_len:]) not in include:\n",
    "          continue\n",
    "    print(dir.name)\n",
    "    if (dir/ \"manual_globals.csv\").exists():\n",
    "        params.loc[dir.name] = np.nan\n",
    "        p = pd.read_csv(dir/\"manual_globals.csv\", index_col=0)\n",
    "        available_paras=[n for n in params.columns if n in p.columns]\n",
    "        params.loc[dir.name, available_paras] = p.loc[dir.name,available_paras]\n",
    "        continue\n",
    "    try:\n",
    "        globs = pd.read_csv(dir/ \"globals.csv\", delimiter=\",\").set_index(\"0\", drop=True).T\n",
    "        available_paras = [n for n in columns if n in globs.columns]\n",
    "        params.loc[dir.name] = globs[available_paras].iloc[1]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"globals file for {dir.name} not found!\")\n",
    "        params.loc[dir.name] = np.nan\n",
    "if experiment == \"scalemask\":\n",
    "     params = pd.read_csv(models_path.parent/\"param1.csv\", index_col=0).sort_values(\"scale_mask\")\n",
    "\n",
    "if agg != None:\n",
    "     params, param_of_interest = functions[agg](params, param_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "eb9b5c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using last\n",
      "run_043\n",
      "last epoch:  9999\n",
      "Initializing parameters from data\n",
      "using last\n",
      "run_045\n",
      "last epoch:  9999\n",
      "Initializing parameters from data\n",
      "using last\n",
      "run_042\n",
      "last epoch:  9999\n",
      "Initializing parameters from data\n",
      "using last\n",
      "run_044\n",
      "last epoch:  9999\n",
      "Initializing parameters from data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/toulouse/miniforge3/envs/bicycle/lib/python3.11/site-packages/pytorch_lightning/utilities/migration/utils.py:55: PossibleUserWarning: The loaded checkpoint was produced with Lightning v2.5.1.post0, which is newer than your current Lightning version: v2.0.9\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    with torch.no_grad():\\n        grn = model.gt_beta.copy()\\n        ckpts[key][\"grn\"] = grn\\n        if not model.mask is None:\\n            beta = np.zeros(grn.shape)\\n            beta[model.mask.cpu().to(bool)] = model.beta_val\\n            ckpts[key][\"beta\"] = beta\\n            #plt.hist(beta)\\n            #plt.show()\\n\\n        else:\\n            ckpts[key][\"beta\"] = model.beta.detach().cpu().numpy().copy()\\n        if not model.bayes_prior is None:\\n            ckpts[key][\"prior\"] = model.bayes_prior.cpu().numpy().copy()\\n'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpts = dict()\n",
    "for path in models_path.iterdir():\n",
    "    key = str(path.name)\n",
    "    if path.name[:-id_len] != prefix:\n",
    "         continue\n",
    "    if int(path.name[-id_len:]) not in include:\n",
    "          continue\n",
    "    paths = glob(root_dir=path/\"customcheckpoint\", pathname=\"./last*.ckpt\")\n",
    "    try:\n",
    "        paths.remove('./last.ckpt')\n",
    "    except:\n",
    "        print(f\"{key} has no last.ckpt\")\n",
    "        params = params.drop(index=key)\n",
    "        continue\n",
    "\n",
    "    if len(paths) ==0:\n",
    "        print(\"using last\")\n",
    "        ckpt_path = path / \"customcheckpoint/last.ckpt\"\n",
    "        if not ckpt_path.exists():\n",
    "            params = params.drop(index=key)\n",
    "\n",
    "            continue\n",
    "    else:\n",
    "        ckpt_path = path / \"customcheckpoint\"/ max(paths)\n",
    "        print(ckpt_path)\n",
    "    print(key)\n",
    "    state = torch.load(ckpt_path, weights_only=False, map_location=\"cpu\")\n",
    "    print(\"last epoch: \",state[\"epoch\"])\n",
    "    if state[\"epoch\"]<1000:\n",
    "         print(f\"{key} only has {state['epoch']} epoch.\\nWill be removed...\")\n",
    "         params = params.drop(index=key)\n",
    "         continue\n",
    "    model = BICYCLE.load_from_checkpoint(ckpt_path).to(\"cpu\")\n",
    "\n",
    "\n",
    "    ckpts[key] = model\n",
    "'''    with torch.no_grad():\n",
    "        grn = model.gt_beta.copy()\n",
    "        ckpts[key][\"grn\"] = grn\n",
    "        if not model.mask is None:\n",
    "            beta = np.zeros(grn.shape)\n",
    "            beta[model.mask.cpu().to(bool)] = model.beta_val\n",
    "            ckpts[key][\"beta\"] = beta\n",
    "            #plt.hist(beta)\n",
    "            #plt.show()\n",
    "\n",
    "        else:\n",
    "            ckpts[key][\"beta\"] = model.beta.detach().cpu().numpy().copy()\n",
    "        if not model.bayes_prior is None:\n",
    "            ckpts[key][\"prior\"] = model.bayes_prior.cpu().numpy().copy()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c302cf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 20 test_genes! Removing last 1 contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/data/toulouse/miniforge3/envs/bicycle/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=2)`.\n",
      "  rank_zero_warn(\n",
      "/data/toulouse/miniforge3/envs/bicycle/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/data/toulouse/miniforge3/envs/bicycle/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=100000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.09 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.09 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.09 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.09 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "More than 20 test_genes! Removing last 1 contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/data/toulouse/miniforge3/envs/bicycle/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=2)`.\n",
      "  rank_zero_warn(\n",
      "/data/toulouse/miniforge3/envs/bicycle/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/data/toulouse/miniforge3/envs/bicycle/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=100000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "More than 20 test_genes! Removing last 1 contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/data/toulouse/miniforge3/envs/bicycle/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=2)`.\n",
      "  rank_zero_warn(\n",
      "/data/toulouse/miniforge3/envs/bicycle/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/data/toulouse/miniforge3/envs/bicycle/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=100000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "More than 20 test_genes! Removing last 1 contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/data/toulouse/miniforge3/envs/bicycle/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=2)`.\n",
      "  rank_zero_warn(\n",
      "/data/toulouse/miniforge3/envs/bicycle/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/data/toulouse/miniforge3/envs/bicycle/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=100000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 0.08 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n",
      "GT_INTERV.DEVICE: cpu\n",
      "setting device to: cpu\n",
      "Training took 0.07 seconds\n",
      "torch.Size([400, 10])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "new_params = pd.DataFrame(columns=[\"nll_\", \"max_f1_\", \"average_precision_\", \"auroc_\", \"prior_average_precision_\", \"prior_auc_\"])\n",
    "for key in params.index:\n",
    "    model = ckpts[key]\n",
    "    if not model.bayes_prior is None:\n",
    "        nll, max_f1, average_precision, auroc, prior_average_precision, prior_auc = evaluate_model(model=model, key = key, models_path=models_path, max_epochs = 100, compare_latents = True)\n",
    "    else:\n",
    "        nll, max_f1, average_precision, auroc = evaluate_model(model=model, key = key, models_path=models_path, max_epochs = 100)\n",
    "        prior_average_precision, prior_auc = [None, None]\n",
    "\n",
    "    new_params.loc[key] = nll, max_f1, average_precision, auroc, prior_average_precision, prior_auc\n",
    "params[new_params.columns] = new_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8d0191d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detangle nll\n",
    "targets = [n for n in params.columns if n.startswith(\"nll\")]\n",
    "params[targets] = params[targets].map(lambda x: x[0] if isinstance(x,tuple) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "dfbe8c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [n for n in params.columns if n.endswith(\"_\")]\n",
    "#params = params.dropna(axis=1, how = \"any\")\n",
    "#means = params.groupby(param_of_interest)[metrics].aggregate(lambda x: np.median(torch.tensor(x).numpy()))\n",
    "#stds = params.groupby(param_of_interest)[metrics].aggregate(np.std)\n",
    "#if np.mean(means[\"nll_\"]) >10:\n",
    "#    means[\"log_nll_\"] = np.log(means[\"nll_\"])\n",
    "#    params[\"log_nll_\"] = np.log(params[\"nll_\"])\n",
    "#    means = means.drop(columns=\"nll_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "03d188e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_source'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "24d77ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nll_',\n",
       " 'max_f1_',\n",
       " 'average_precision_',\n",
       " 'auroc_',\n",
       " 'prior_average_precision_',\n",
       " 'prior_auc_']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "4e73d74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant p-values: {}\n",
      "Significant p-values: {}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving! Path: ./presentation/onlybicycle_data_full_metrics_bar\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "from matplotlib.colors import TABLEAU_COLORS\n",
    "colors = list(TABLEAU_COLORS.values())\n",
    "#colors = [\"salmon\", \"skyblue\"]\n",
    "width=1\n",
    "fig, ax = plt.subplots(figsize=(width*len(params)+5, 6), ncols=2)\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Group info\n",
    "ex_metrics = ['max_f1_', 'average_precision_', 'auroc_',\n",
    "              \"prior_auc_\", \"prior_average_precision_\"\n",
    "              ]\n",
    "df = params[ex_metrics+[param_of_interest]]#.query(f\"{param_of_interest}!=1\")\n",
    "p_dict = bar_scientific(df = df, param_of_interest=param_of_interest, ax = ax[0], colors = colors, bar_width=width, annotate=False)\n",
    "\n",
    "ex_metrics = ['nll_']\n",
    "\n",
    "df = params[ex_metrics+[param_of_interest]]\n",
    "p_dict.update(bar_scientific(df = df, param_of_interest=param_of_interest, ax = ax[1], colors = colors, bar_width=width), annotate=False)\n",
    "\n",
    "\n",
    "fig.suptitle(f\"{experiment} Comparing {param_of_interest}\")\n",
    "#fig.legend(labels=np.unique(df[param_of_interest]), labelcolor = colors)\n",
    "ax[0].legend(loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "if save:\n",
    "    path = f\"./presentation/{experiment}_full_metrics_bar\"\n",
    "    print(f\"Saving! Path: {path}\")\n",
    "    fig.savefig(path +\".pdf\")\n",
    "    with open(path + \".json\", \"w\") as wf:\n",
    "        json.dump(p_dict, wf)\n",
    "    params.to_csv(path+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f399e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5c7f8c7",
   "metadata": {},
   "source": [
    "df.columns.drop(param_of_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e97a47",
   "metadata": {},
   "source": [
    "log_nll = np.mean(means[\"nll_\"]) >10\n",
    "nlls = means[\"nll_\"]\n",
    "means = means.drop(columns=\"nll_\")\n",
    "nll_stds = stds[\"nll_\"]\n",
    "stds = stds.drop(columns=\"nll_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd750c",
   "metadata": {},
   "source": [
    "nlls.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc70bbc6",
   "metadata": {},
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca8b73d",
   "metadata": {},
   "source": [
    "width = 0.1\n",
    "a = 0.005\n",
    "plt.subplot(1,3,(1,2))\n",
    "x = np.arange(means.shape[1])\n",
    "for i,row in means.iterrows():\n",
    "    y = row.values\n",
    "    plt.bar(x = x, height = y, label = row.name, width=width)\n",
    "    plt.errorbar(x = x, y = y, c = \"black\", yerr=stds.loc[i], fmt=\"none\")\n",
    "    x = x + width\n",
    "\n",
    "plt.xticks(ticks = np.arange(means.shape[1]) + width*(0.25*len(means)), labels=means.columns)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "x = np.arange(0, len(nlls)*width*2, width*2)\n",
    "plt.bar(x = x, height = nlls, label = nlls.index, width=width)\n",
    "plt.errorbar(x = x, y = nlls, c = \"black\", yerr=nll_stds, fmt=\"none\")\n",
    "plt.xticks(ticks=0.1, labels=\"nll\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "plt.title(f\"{experiment}\")\n",
    "xticks = np.array(plt.xticks()[0])\n",
    "a = 0.05\n",
    "#for m, metric in enumerate(means.columns):\n",
    "#    bar_height = 0\n",
    "#    scores = means[metric]\n",
    "#    for c1, _ in enumerate(scores):\n",
    "#        y1 = params.query(f\"{param_of_interest} == '{scores.index[c1]}'\")[metric].apply(np.array)\n",
    "#        print(c1, y1)\n",
    "#        for c2, _ in enumerate(scores):\n",
    "#            y2 = params.query(f\"{param_of_interest} == '{scores.index[c2]}'\")[metric].apply(np.array)\n",
    "#\n",
    "#            if c1 >= c2:\n",
    "#                # continue when comparing same row\n",
    "#                continue\n",
    "#            print(c2, y2)\n",
    "#            p = np.round(ttest_rel(y1, y2).pvalue, 5)\n",
    "#            print(f\"p value of: {metric} in {scores.index[c1]} vs {scores.index[c2]} is {p}\")\n",
    "#            if p>a:\n",
    "#                # continue if not significant\n",
    "#                continue\n",
    "#            y_bar1 = np.max([y1, y2]) *(1.1+bar_height*0.2)\n",
    "#            y_bar2 = y_bar1 +0.1\n",
    "#            x1 = xticks[c1+1+m*len(scores)]\n",
    "#            x2 = xticks[c1+1+m*len(scores)]+width\n",
    "#            plt.plot(np.repeat([x1, x2], 2), np.array([y_bar1, y_bar2])[[0,1,1,0]], c = \"black\")\n",
    "#            y_text = y_bar2 +0.1\n",
    "#            x_text = np.mean([x1, x2])\n",
    "#            plt.ylim((0, y_text*1.1))\n",
    "#            p = f\"p value: {p}\"\n",
    "#            plt.text(x = x_text, y = y_text, s = p, ha=\"center\")\n",
    "#            bar_height += 1\n",
    "#            #plt.ylim((0, y_text*1.2))\n",
    "plt.plot([], [], \" \", label = param_of_interest + \":\")\n",
    "plt.legend()\n",
    "if save:\n",
    "    path = Path(f\"./presentation/{experiment}_newmetrics_bar.pdf\")\n",
    "    print(f\"saving to: {path}\")\n",
    "    plt.savefig(path)\n",
    "    params.to_csv(path.parent/f\"{experiment}_newmetrics_bar.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa05f629",
   "metadata": {},
   "source": [
    "len(model.test_gene_ko)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe1ebb4",
   "metadata": {},
   "source": [
    "# plot figures from paper\n",
    "# extract from np tuple\n",
    "pattern = re.compile(\"(?<=\\()\\d+\\.*\\d+(?=\\))\")\n",
    "# Sem1:\n",
    "config = \"linear-ou\"\n",
    "nll = params.query(f'data_sem == \"{config}\"')[\"nll\"]\n",
    "means = nll.map(lambda x: float(re.findall(pattern, x)[0]))\n",
    "errors = nll.map(lambda x: float(re.findall(pattern, x)[1]))\n",
    "mean = np.mean(means)\n",
    "error = np.sqrt(np.square(errors).sum())\n",
    "error = np.std(means)\n",
    "plt.bar(x = config, height=mean)\n",
    "plt.errorbar(x=config, y= mean, yerr=error, fmt=\"none\",c = \"red\", capsize=10)\n",
    "plt.show()\n",
    "config = \"linear\"\n",
    "nll = params.query(f'data_sem == \"{config}\"')[\"nll\"]\n",
    "means = nll.map(lambda x: float(re.findall(pattern, x)[0]))\n",
    "errors = nll.map(lambda x: float(re.findall(pattern, x)[1]))\n",
    "mean = np.mean(means)\n",
    "error = np.sqrt(np.square(errors).sum())\n",
    "error = np.std(means)\n",
    "plt.bar(x = config, height=mean)\n",
    "plt.errorbar(x=config, y= mean, yerr=error, fmt=\"none\",c = \"red\", capsize=10)\n",
    "\n",
    "plt.ylabel(\"Log-NLL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3ea725",
   "metadata": {},
   "source": [
    "# transform functions\n",
    "pdt = torch.distributions.PositiveDefiniteTransform()\n",
    "def mat_prod(m):\n",
    "    # performs very badly\n",
    "    return torch.matmul(m, m.T)\n",
    "def cholesky(m):\n",
    "    transform = torch.distributions.LowerCholeskyTransform()\n",
    "    m_t = transform(m)\n",
    "    return m_t + m_t.T\n",
    "t_func = [pdt, cholesky]\n",
    "\n",
    "# distribution func\n",
    "def normal(z_bar, omega):\n",
    "    return torch.distributions.Normal(loc=z_bar, scale = torch.sqrt(torch.diag(omega)))\n",
    "def mvn(z_bar, omega):\n",
    "    return torch.distributions.MultivariateNormal(loc=z_bar, covariance_matrix=omega)\n",
    "dists = [normal, mvn]\n",
    "configs = [\n",
    "    {\n",
    "    \"compare_latents\":False,\n",
    "    \"latents_sampled\":False,\n",
    "    \"omega_transform\":None,\n",
    "    \"dist\":None\n",
    "    },\n",
    "    {\n",
    "    \"compare_latents\":True,\n",
    "    \"latents_sampled\":True,\n",
    "    \"omega_transform\":pdt,\n",
    "    \"dist\":normal,\n",
    "    }\n",
    "]\n",
    "configs2 = [\n",
    "    {\n",
    "    \"compare_latents\":False,\n",
    "    \"latents_sampled\":False,\n",
    "    \"omega_transform\":None,\n",
    "    \"dist\":None\n",
    "    },\n",
    "    {\n",
    "    \"compare_latents\":False,\n",
    "    \"latents_sampled\":False,\n",
    "    \"omega_transform\":pdt,\n",
    "    \"dist\":normal,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243eaa7d",
   "metadata": {},
   "source": [
    "SEED = 1\n",
    "iterator = [0, 1]\n",
    "validation_size = 0\n",
    "batch_size = 10000\n",
    "scores = np.empty((len(ckpts.keys()), len(iterator)))\n",
    "for k, (key, model) in enumerate(ckpts.items()):\n",
    "    print(key)\n",
    "    \n",
    "    for n,i in enumerate(iterator):\n",
    "        print(f\"Iterator state: {i}\")\n",
    "        scores[k,n] = evaluate_model(model, key=key, models_path=models_path, max_epochs = 1000, compute_class_metrics = False, **configs[i])[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a68851",
   "metadata": {},
   "source": [
    "y = np.mean(scores, axis = 0)\n",
    "x=np.array(iterator).astype(str)\n",
    "plt.bar(x=x, height=y, alpha = 0.9)\n",
    "plt.errorbar(x=x, y=y,yerr=np.std(scores, axis = 0), fmt=\"none\", c = \"grey\", capsize=10)\n",
    "xticks = np.array(plt.xticks()[0])\n",
    "a = 0.01\n",
    "n_sign = 0\n",
    "# enumerate pairs and test for significance\n",
    "for c1 in range(scores.shape[1]):\n",
    "    for c2 in range(scores.shape[1]):\n",
    "        if c1 >= c2:\n",
    "            # continue when comparing same column\n",
    "            continue\n",
    "        p = np.round(ttest_rel(scores[:,c1], scores[:,c2]).pvalue, 5)\n",
    "        if p>a:\n",
    "            # continue if not significant\n",
    "            continue\n",
    "        y_bar1 = np.max(y) *(1.1+n_sign*0.2)\n",
    "        y_bar2 = y_bar1 *1.1\n",
    "        plt.plot(np.repeat(xticks[[c1, c2]], 2), np.array([y_bar1, y_bar2])[[0,1,1,0]], c = \"black\")\n",
    "        y_text = y_bar2 *1.01\n",
    "        x_text = np.mean(xticks[[c1, c2]])\n",
    "        plt.ylim((0, y_text*1.1))\n",
    "        p = f\"p value: {p}\"\n",
    "        plt.text(x = x_text, y = y_text, s = p, ha=\"center\")\n",
    "        n_sign += 1\n",
    "        plt.ylim((0, y_text*1.2))\n",
    "plt.xlabel(\"use_loss_funct\")\n",
    "plt.ylabel(\"NLL\")\n",
    "plt.title(\"Selection Summary\")\n",
    "#plt.legend()\n",
    "#plt.savefig(Path(f\"./presentation/NLL_{experiment}_SEM2_lossfunct.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0016e",
   "metadata": {},
   "source": [
    "SEED = 1\n",
    "iterator = np.power(10, np.arange(4), dtype=int)\n",
    "validation_size = 0\n",
    "batch_size = 10000\n",
    "scores = np.empty((len(ckpts.keys()), len(iterator)))\n",
    "for k, (key, model) in enumerate(ckpts.items()):\n",
    "    print(key)\n",
    "    \n",
    "    for n,i in enumerate(iterator):\n",
    "        print(f\"Iterator state: {i}\")\n",
    "        nll = evaluate_model(model, key=key, models_path=models_path, max_epochs = int(i), compute_class_metrics = False, **configs[0])[0]\n",
    "        scores[k,n] = nll\n",
    "    plt.plot(iterator, np.log(scores[k]), label=key)\n",
    "plt.xlabel(\"OmegaIterative epochs\")\n",
    "plt.ylabel(\"log NLL\")\n",
    "plt.title(\"NLL\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f329ae91",
   "metadata": {},
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d66a83",
   "metadata": {},
   "source": [
    "SEED = 1\n",
    "iterator = np.power(10, np.arange(4))\n",
    "cols = [\"nll\"]\n",
    "validation_size = 0\n",
    "batch_size = 10000\n",
    "for key, model in ckpts.items():\n",
    "    scores = pd.DataFrame(columns=cols)\n",
    "    samples = torch.tensor(np.load(models_path/key/\"synthetic_data\"/\"check_sim_samples.npy\"))\n",
    "    sim_regime = torch.tensor(np.load(models_path/key/\"synthetic_data\"/\"check_sim_regimes.npy\"))\n",
    "    beta = torch.tensor(np.load(models_path/key/\"synthetic_data\"/\"check_sim_beta.npy\"))\n",
    "    train_gene_ko = model.train_gene_ko\n",
    "    test_gene_ko = model.test_gene_ko\n",
    "    train_loader, validation_loader, test_loader = create_loaders(\n",
    "        samples=samples, # test_loader is None\n",
    "        sim_regime=sim_regime,\n",
    "        validation_size=validation_size,\n",
    "        batch_size=batch_size,\n",
    "        SEED= SEED,\n",
    "        train_gene_ko=train_gene_ko,\n",
    "        test_gene_ko=test_gene_ko,\n",
    "        persistent_workers=False,\n",
    "        covariates=None,\n",
    "        num_workers= 1,\n",
    "    )\n",
    "\n",
    "    for n in iterator:\n",
    "        print(n)\n",
    "        scores.loc[len(scores)] = [model.evaluate(test_loader.dataset, compare_latents=False, max_epochs = int(n))][0]\n",
    "    plt.plot(iterator, np.log(scores), label=key)\n",
    "    break\n",
    "plt.xlabel(\"OmegaIterative epochs\")\n",
    "plt.ylabel(\"log NLL\")\n",
    "plt.title(\"NLL\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2e69e",
   "metadata": {},
   "source": [
    "nll = scores\n",
    "nll = nll.map(lambda x: x[0])\n",
    "plt.plot(iterator, np.log(nll))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f3fba0",
   "metadata": {},
   "source": [
    "nll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f9936f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc9336f",
   "metadata": {},
   "source": [
    "nll = scores\n",
    "nll = nll.map(lambda x: x[0])\n",
    "plt.plot(iterator, np.log(nll))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf7f49a",
   "metadata": {},
   "source": [
    "nll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c691beb6",
   "metadata": {},
   "source": [
    "nll = scores[\"nll\"]\n",
    "nll = nll.map(lambda x: x[0])\n",
    "plt.plot(iterator, np.log(nll))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6e5197",
   "metadata": {},
   "source": [
    "nll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd4dfb0",
   "metadata": {},
   "source": [
    "def unseen_nll(model:BICYCLE,\n",
    "               unseen_contexts:list, # list of target gene indexes for each sample\n",
    "               unseen_data_csv:Path, # path to samples # at least samples_per_pert for each context\n",
    "               samples_per_pert:int = 5, \n",
    "               target_mu=[],\n",
    "               target_std=[],\n",
    "               ):\n",
    "    if target_mu is []:\n",
    "        target_mu = np.median(model.alpha_p.detach().numpy())\n",
    "    if target_std is []:\n",
    "        target_std = np.median(model.sigma_p.detach().numpy())\n",
    "    # read data\n",
    "    samples = pd.read_csv(unseen_data_csv, index_col=0)\n",
    "\n",
    "    contexts= list(set(unseen_contexts))\n",
    "    sample_target_idxs = [unseen_contexts.index(c) for c in contexts]\n",
    "    print(contexts)\n",
    "    nlls = []\n",
    "    for n, targets in enumerate(contexts):\n",
    "        if targets == np.nan:\n",
    "            continue\n",
    "        if not type(targets) is list:\n",
    "            targets = [targets]\n",
    "        target_samples = torch.tensor(samples.iloc[sample_target_idxs[n]:sample_target_idxs[n]+samples_per_pert].to_numpy())\n",
    "        z_bar, omega = model.predict_perturbation(\n",
    "            target_idx = [*targets], # target index in genes\n",
    "            target_mu=target_mu,\n",
    "            target_std=target_std,\n",
    "            max_epochs=5000,\n",
    "            perturbation_type=[],\n",
    "            perturbation_like=[],\n",
    "            )\n",
    "\n",
    "        nll = model.test_nll(\n",
    "            z_bar = z_bar+torch.abs(z_bar.min()),\n",
    "            omega = omega,  # var = scale**2\n",
    "            samples = target_samples,\n",
    "            )\n",
    "\n",
    "        nlls.append(nll)\n",
    "    return nlls\n",
    "\n",
    "\n",
    "key = \"run_042\"\n",
    "data_id = params.loc[key, \"data_id\"]\n",
    "model = ckpts[key].to(\"cpu\")\n",
    "samples_per_pert=10\n",
    "#with open(data_path/data_id/\"unseen_target_genes.json\", \"r\") as rf:\n",
    "#    target_genes = json.load(rf)\n",
    "if params.loc[key, \"data_source\"] == \"scMultiSim\":\n",
    "    adata = sc.read_h5ad(data_path/\"scMultiSim_data\"/params.loc[key, \"data_id\"]/\"ready_full_rna.h5ad\",)\n",
    "    samples = adata.X.copy()\n",
    "    TFs = np.arange(10)\n",
    "    target_genes = np.repeat(TFs, 400)\n",
    "    target_genes = np.concatenate([np.full((8000),np.nan), target_genes])\n",
    "    mask = np.isnan(target_genes)\n",
    "    samples = samples[~mask]\n",
    "    unseen_contexts = target_genes[~mask]\n",
    "else:\n",
    "    samples = np.load(models_path/key/\"synthetic_data\"/\"check_sim_samples.npy\")\n",
    "    sim_regime = np.load(models_path/key/\"synthetic_data\"/\"check_sim_regimes.npy\")\n",
    "    gt_interv = np.load(models_path/key/\"synthetic_data\"/\"check_sim_gt_interv.npy\")\n",
    "    contexts = gt_interv[:,sim_regime].astype(bool).T\n",
    "    gene_idxs = np.arange(samples.shape[1])\n",
    "    target_genes = [tuple(gene_idxs[c]) for c in contexts if c.any()]\n",
    "    samples = samples[-len(target_genes):]\n",
    "(data_path/\"/tmp\").mkdir(exist_ok=True)\n",
    "pd.DataFrame(samples).to_csv(data_path/\"tmp\"/\"samples.csv\")\n",
    "nlls= unseen_nll(model=model,\n",
    "           unseen_contexts=target_genes,\n",
    "           unseen_data_csv=data_path/\"tmp\"/\"samples.csv\",\n",
    "           samples_per_pert=samples_per_pert,\n",
    "           target_mu=[0.1],\n",
    "           target_std=[0.2]\n",
    "           )\n",
    "\n",
    "plt.hist(nlls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4267b",
   "metadata": {},
   "source": [
    "key = \"run_055\"\n",
    "data_id = params.loc[key, \"data_id\"]\n",
    "model = ckpts[key].to(\"cpu\")\n",
    "samples_per_pert=1\n",
    "\n",
    "target_genes = np.load(data_path/data_id/\"unseen_target_genes.npy\")\n",
    "unseen_data_csv = data_path/data_id/\"unseen_rna_matrix.csv\"\n",
    "\n",
    "nlls= unseen_nll(model=model,\n",
    "           unseen_contexts=target_genes,\n",
    "           unseen_data_csv=unseen_data_csv,\n",
    "           samples_per_pert=samples_per_pert,\n",
    "           target_mu=[0.1],\n",
    "           target_std=[0.2]\n",
    "           )\n",
    "\n",
    "plt.hist(nlls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af4554",
   "metadata": {},
   "source": [
    "key = \"run_042\"\n",
    "model = ckpts[key].to(\"cpu\")\n",
    "\n",
    "target_idx = 0\n",
    "grn = model.gt_beta.numpy().copy()\n",
    "if params.loc[key, \"data_source\"] == \"scMultiSim\":\n",
    "    adata = sc.read_h5ad(data_path/\"scMultiSim_data\"/params.loc[key, \"data_id\"]/\"ready_full_rna.h5ad\",)\n",
    "    samples = adata.X.copy()\n",
    "    samples = samples[8000 + (400*target_idx):8400+(400*(target_idx+1))]\n",
    "else:\n",
    "    samples = np.load(models_path/key/\"synthetic_data\"/\"check_sim_samples.npy\")\n",
    "    print(\"samples: shape\",samples.shape)\n",
    "    sim_regime = np.load(models_path/key/\"synthetic_data\"/\"check_sim_regimes.npy\")\n",
    "    gt_interv = np.load(models_path/key/\"synthetic_data\"/\"check_sim_gt_interv.npy\")\n",
    "    contexts = gt_interv[:,sim_regime]    \n",
    "    samples = samples[np.argmax(contexts, axis=0) == target_idx]\n",
    "\n",
    "target_mu = np.median(model.alpha_p.detach().numpy())\n",
    "target_std = np.median(model.sigma_p.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c1a0af",
   "metadata": {},
   "source": [
    "z_bar, omega = model.predict_perturbation(target_idx = [target_idx],\n",
    "    target_mu=[target_mu],\n",
    "    target_std=[target_std],\n",
    "    max_epochs=1000,\n",
    "    perturbation_type=[],\n",
    "    perturbation_like=[],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89027f",
   "metadata": {},
   "source": [
    "omega.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af69a5de",
   "metadata": {},
   "source": [
    "nlls = []\n",
    "for s in torch.tensor(samples):\n",
    "    nlls.append(model.test_nll(z_bar = z_bar+torch.abs(z_bar.min()),\n",
    "        omega = omega,\n",
    "        samples = s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fefd9ce",
   "metadata": {},
   "source": [
    "plt.hist(nlls, bins=50, density=True)\n",
    "print(np.std(nlls))\n",
    "print(np.mean(nlls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00a58b1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bicycle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
