{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33af5071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19f88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = Path(\"/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models\")\n",
    "PLOTS_PATH = Path(\"/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/plots\")\n",
    "ANALYSIS_PATH = Path(\"/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/analysis\")\n",
    "exclude=[\"test_run_00013\", \"test_run_00014\", \"figures\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a367dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_id        profile scale compile full dynamic mode     name\n",
    "compiler_params = pd.DataFrame([\n",
    "    [\"test_run_00061\", True, 2.5, False, False, False , None, \"non_compiled\"],\n",
    "    [\"test_run_00062\", True, 2.5, True, True, False, None, \"fullgraph\"],\n",
    "    [\"test_run_00063\", True, 2.5, True, False, True, None, \"dynamic\"],\n",
    "    [\"test_run_00059\", True, 2.5, True, False, False, \"reduce-overhead\", \"reduce_overhead\"],\n",
    "    [\"test_run_00060\", True, 2.5, True, False, False, None, \"vanilla compiled\"],\n",
    "], columns=[\"run_id\", \"profile\", \"scale_factor\", \"compile\", \"compile_full\", \"compile_dynamic\", \"compile_mode\", \"name\"])\n",
    "compiler_keys = compiler_params[\"run_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8caa00",
   "metadata": {},
   "source": [
    "## Summary profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d2d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_profiles = dict()\n",
    "for dir in ANALYSIS_PATH.iterdir():\n",
    "    if str(dir.name) in exclude:\n",
    "        continue\n",
    "    if dir.is_dir() and dir.name in compiler_keys.to_list():\n",
    "        training_profiles[str(dir.name)] = pd.read_csv(dir.joinpath(\"training_profile.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65015f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_profiles.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate filtered profiled time\n",
    "times = list()\n",
    "for key in compiler_keys:\n",
    "    print(key)\n",
    "    times.append(training_profiles[key][\"Time\"].sum())\n",
    "compiler_params[\"Profile_Time\"] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(compiler_params.sort_values(\"Profile_Time\"),\n",
    "       x=\"run_id\",\n",
    "       y=\"Profile_Time\",\n",
    "       text=\"name\",\n",
    "       color=\"compile\",\n",
    "       title=\"Comparison of profiled time with different compilation options\"\n",
    "       )\n",
    "fig.show()\n",
    "fig.write_image(ANALYSIS_PATH/\"figures\"/\"Compiled_model_runtime.pdf\", scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = {\n",
    "    \"Class\": lambda x: x.iloc[0],\n",
    "    \"Function\": lambda x: x.iloc[0],\n",
    "    \"Class_Function_etc\": lambda x: x.iloc[0],\n",
    "    \"Class_Function\": lambda x: x.iloc[0],\n",
    "    \"Summary_index\": lambda x: x.iloc[0],\n",
    "    \"filename_lineno(function)\": lambda x: x.iloc[0],\n",
    "    \"is_callback\": lambda x: x.iloc[0],\n",
    "    \"Call_num\": \"sum\",\n",
    "    \"Primitive_Call_num\": \"sum\",\n",
    "    \"Time\": \"sum\",\n",
    "    \"ncalls\": \"sum\",\n",
    "    \"tot_time\": \"sum\",\n",
    "    \"tot_percall\": \"mean\",\n",
    "    \"cum_time\": \"sum\",\n",
    "    \"cum_percall\": \"mean\",    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a5cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_profiles = dict()\n",
    "for dir in ANALYSIS_PATH.iterdir():\n",
    "    if str(dir.name) in exclude:\n",
    "        continue\n",
    "    if dir.is_dir() and dir.name in compiler_keys.to_list():\n",
    "        df = pd.read_csv(dir.joinpath(\"full_training_profile.csv\")).drop(columns = [\"Rank\"])\n",
    "        df = df.groupby([\"Class_Function_etc\"], as_index=False, ).agg(aggregator).reset_index()\n",
    "        df[\"in_model\"] = df[\"Class_Function_etc\"].apply(lambda x: \"model.py\" in str(x).casefold())\n",
    "        df[\"in_bicycle\"] = df[\"Class_Function_etc\"].apply(lambda x: \"bicycle\" in str(x).casefold())\n",
    "        df = df.sort_values(\"filename_lineno(function)\").set_index(pd.Index(np.arange(len(df))),drop=True)\n",
    "        #numericals = [\"Call_num\",\"Primitive_Call_num\",\"Time\",\"ncalls\",\"tot_time\",\"tot_percall\",\"cum_time\",\"cum_percall\"]\n",
    "        #df[numericals] = df[numericals]/sum(df[numericals], axis=0)\n",
    "        full_profiles[str(dir.name)] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0788b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7564d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"ncalls\",\"tot_time\",\"tot_percall\",\"cum_time\",\"cum_percall\"]\n",
    "compiler_params=compiler_params.set_index(\"run_id\")\n",
    "condition=\"in_bicycle\"\n",
    "top_df = pd.DataFrame(columns=df.columns.append(compiler_params.columns))\n",
    "for metric in metrics:\n",
    "    for n, df in full_profiles.items():\n",
    "        data = df.query(condition).sort_values(metric, ignore_index=True, ascending = False).iloc[:10]\n",
    "        for _, row in data.iterrows():\n",
    "            top_df.loc[len(top_df)] = np.concatenate([row, compiler_params.loc[n]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6240a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    title = f\"Compiled {metric} of functions with {condition}\"\n",
    "    fig = px.bar(top_df.sort_values(metric),\n",
    "    x = \"filename_lineno(function)\",\n",
    "    y = metric,\n",
    "    color= \"name\",\n",
    "#    log_y = True,\n",
    "    text=\"Function\",\n",
    "    title=title,\n",
    "    barmode=\"group\"\n",
    "    )\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
