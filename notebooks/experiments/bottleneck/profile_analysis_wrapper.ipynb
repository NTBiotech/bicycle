{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33af5071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19f88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = Path(\"/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models\")\n",
    "PLOTS_PATH = Path(\"/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/plots\")\n",
    "ANALYSIS_PATH = Path(\"/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/analysis\")\n",
    "exclude=[\"test_run_00013\", \"test_run_00014\", \"figures\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a367dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_id        profile scale compile full dynamic mode     name\n",
    "parameters= pd.read_csv(ANALYSIS_PATH/\"parameters.csv\").set_index(\"run_id\").sort_index()\n",
    "\n",
    "wrapper_keys = [\"test_run_00081\",\n",
    "    \"test_run_00082\",\n",
    "    \"test_run_00084\",\n",
    "    \"test_run_00085\",\n",
    "    ]\n",
    "wrapper_names = [\"wrapper_non_compiled\",\n",
    "                 \"wrapper_compiled\",\n",
    "                 \"wrapper_compiled_with_count\",\n",
    "                 \"no_wrapper_non_compiled\"]\n",
    "parameters = parameters.loc[wrapper_keys]\n",
    "parameters[parameters.isna()] = np.nan\n",
    "\n",
    "parameters[\"name\"] = wrapper_names\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a6d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_key = \"test_run_00060\"\n",
    "manual_params = pd.read_csv(ANALYSIS_PATH/\"manual_params.csv\").set_index(\"run_id\").loc[compiled_key]\n",
    "parameters.loc[compiled_key] = manual_params\n",
    "wrapper_keys.append(compiled_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c49d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8caa00",
   "metadata": {},
   "source": [
    "## Summary profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d2d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_profiles = dict()\n",
    "for dir in ANALYSIS_PATH.iterdir():\n",
    "    if str(dir.name) in exclude:\n",
    "        continue\n",
    "    if dir.is_dir() and dir.name in wrapper_keys:\n",
    "        training_profiles[str(dir.name)] = pd.read_csv(dir.joinpath(\"training_profile.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate filtered profiled time\n",
    "times = list()\n",
    "for key in wrapper_keys:\n",
    "    print(key)\n",
    "    times.append(training_profiles[key][\"Time\"].sum())\n",
    "parameters[\"Profile_Time\"] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(parameters.sort_values(\"Profile_Time\").reset_index(),\n",
    "       x=\"run_id\",\n",
    "       y=\"Profile_Time\",\n",
    "       text=\"name\",\n",
    "       color=\"compile\",\n",
    "       title=\"Comparison of profiled time with different .to()-wrapper options\"\n",
    "       )\n",
    "fig.show()\n",
    "fig.write_image(ANALYSIS_PATH/\"figures\"/\"Wrapper_model_runtime.pdf\", scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = {\n",
    "    \"Class\": lambda x: x.iloc[0],\n",
    "    \"Function\": lambda x: x.iloc[0],\n",
    "    \"Class_Function_etc\": lambda x: x.iloc[0],\n",
    "    \"Class_Function\": lambda x: x.iloc[0],\n",
    "    \"Summary_index\": lambda x: x.iloc[0],\n",
    "    \"filename_lineno(function)\": lambda x: x.iloc[0],\n",
    "    \"is_callback\": lambda x: x.iloc[0],\n",
    "    \"Call_num\": \"sum\",\n",
    "    \"Primitive_Call_num\": \"sum\",\n",
    "    \"Time\": \"sum\",\n",
    "    \"ncalls\": \"sum\",\n",
    "    \"tot_time\": \"sum\",\n",
    "    \"tot_percall\": \"mean\",\n",
    "    \"cum_time\": \"sum\",\n",
    "    \"cum_percall\": \"mean\",    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a5cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_profiles = dict()\n",
    "for dir in ANALYSIS_PATH.iterdir():\n",
    "    if str(dir.name) in exclude:\n",
    "        continue\n",
    "    if dir.is_dir() and dir.name in wrapper_keys.to_list():\n",
    "        df = pd.read_csv(dir.joinpath(\"full_training_profile.csv\")).drop(columns = [\"Rank\"])\n",
    "        df = df.groupby([\"Class_Function_etc\"], as_index=False, ).agg(aggregator).reset_index()\n",
    "        df[\"in_model\"] = df[\"Class_Function_etc\"].apply(lambda x: \"model.py\" in str(x).casefold())\n",
    "        df[\"in_bicycle\"] = df[\"Class_Function_etc\"].apply(lambda x: \"bicycle\" in str(x).casefold())\n",
    "        df = df.sort_values(\"filename_lineno(function)\").set_index(pd.Index(np.arange(len(df))),drop=True)\n",
    "        #numericals = [\"Call_num\",\"Primitive_Call_num\",\"Time\",\"ncalls\",\"tot_time\",\"tot_percall\",\"cum_time\",\"cum_percall\"]\n",
    "        #df[numericals] = df[numericals]/sum(df[numericals], axis=0)\n",
    "        full_profiles[str(dir.name)] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0788b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7564d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"ncalls\",\"tot_time\",\"tot_percall\",\"cum_time\",\"cum_percall\"]\n",
    "#compiler_params=compiler_params.set_index(\"run_id\")\n",
    "condition=\"in_bicycle\"\n",
    "top_df = pd.DataFrame(columns=df.columns.append(parameters.columns))\n",
    "for metric in metrics:\n",
    "    for n, df in full_profiles.items():\n",
    "        data = df.query(condition).sort_values(metric, ignore_index=True, ascending = False).iloc[:10]\n",
    "        for _, row in data.iterrows():\n",
    "            top_df.loc[len(top_df)] = np.concatenate([row, parameters.loc[n]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6240a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    title = f\"Compiled {metric} of functions with {condition}\"\n",
    "    fig = px.bar(top_df.sort_values(metric),\n",
    "    x = \"filename_lineno(function)\",\n",
    "    y = metric,\n",
    "    color= \"name\",\n",
    "#    log_y = True,\n",
    "    text=\"Function\",\n",
    "    title=title,\n",
    "    barmode=\"group\"\n",
    "    )\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bicycle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
