{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d22de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import pstats as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = Path(\"/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models\")\n",
    "PLOTS_PATH = Path(\"/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/plots\")\n",
    "ANALYSIS_PATH = Path(\"/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/analysis\")\n",
    "exclude=[\"test_run_00013\", \"test_run_00014\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d04c89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_profile(path: Path, rank: bool = False):\n",
    "    \"\"\"\n",
    "    Function to parse a 'FIT Profiler Report' from a textfile. \n",
    "\n",
    "    Returns:\n",
    "    tuple: (\n",
    "        df: pd.DataFrame containing all profiling data,\n",
    "        df_sum: pd.DataFrame containing data for the function)\n",
    "    \"\"\"\n",
    "    print(f\"Parsing file: {path}\")\n",
    "    with open(path, \"r\") as rf:\n",
    "        parsed_file = rf.read()\n",
    "    parsed_file = parsed_file.split(\"\\n\\n\\n\")\n",
    "    \n",
    "    column_names = [\"ncalls\", \"tot_time\", \"tot_percall\", \"cum_time\", \"cum_percall\", \"filename:lineno(function)\", \"Class\", \"Function\", \"Call_num\", \"Primitive_Call_num\", \"Time\", \"Rank\", \"Summary_index\",]\n",
    "    \n",
    "    class_pattern = re.compile(\"\\[\\S+(?=\\.)\")\n",
    "    function_pattern = re.compile(\"\\w+(?=#)\")\n",
    "    callnum_pattern = re.compile(\"(?<=\\s\\s\\s)\\d+\")\n",
    "    primcallnum_pattern = re.compile(\"(?<=\\()\\d+\")\n",
    "    time_pattern= re.compile(\"\\d+\\.\\d\\d\\d\")\n",
    "    rank_pattern = re.compile(\":\\s\\d*\\s\")\n",
    "    patterns = [class_pattern, function_pattern, callnum_pattern, primcallnum_pattern, time_pattern, rank_pattern]\n",
    "\n",
    "    df_sum = pd.DataFrame(columns=column_names[6:-1])\n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "    for n, section in enumerate(parsed_file):\n",
    "        section = section.split(\"\\n\")\n",
    "        title = \"#\".join(section[1:3])\n",
    "\n",
    "        title_columns = [re.findall(pat, title) for pat in patterns]\n",
    "        title_columns = [str(s[0]) if len(s)>0 else pd.NA for s in title_columns]\n",
    "        df_sum.loc[len(df_sum)] = title_columns\n",
    "        \n",
    "        title_columns.append(len(df_sum)-1)\n",
    "        for line in section[7:]:\n",
    "            \n",
    "            split = line.split(\" \")\n",
    "            while \"\" in split:\n",
    "                split.remove(\"\")\n",
    "            if \"/\" in split[0]:\n",
    "                split[0] = split[0].split(\"/\")[0]\n",
    "\n",
    "            df.loc[len(df), column_names[:5]] = split[:5]\n",
    "            if re.findall(\"{.+}\", line) != []:\n",
    "                #print(re.findall(\"{.+}\", line))\n",
    "                df.iloc[len(df)-1, 5] = str(re.findall(\"{.+}\", line)[0])\n",
    "            else:\n",
    "                #print(\"split\", split[-1])\n",
    "                df.iloc[len(df)-1, 5] = split[-1]\n",
    "\n",
    "            df.iloc[len(df)-1, 6:] = title_columns\n",
    "        \n",
    "            \n",
    "    return df, df_sum.iloc[:-1]\n",
    "\n",
    "#read_profile(\"/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00030/profiler/fit-training_profile.txt\")[1].iloc[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9584861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_profiler_records(df, df_sum):\n",
    "    print(\"Filtering...\")\n",
    "    df_sum=df_sum.astype({\"Time\": float,\n",
    "                          \"Call_num\": int})\n",
    "    df = df.astype({\"tot_time\": float,\n",
    "                        \"ncalls\": int})\n",
    "    clean_df = pd.DataFrame(columns=df.columns)\n",
    "    for func_index, function in df_sum.Function.items():\n",
    "        profiler_time = 0.0\n",
    "        profiler_calls = 0\n",
    "        sub_sel = df.loc[df[\"Function\"] == function]\n",
    "        for _, row in sub_sel.iterrows():\n",
    "            if \"profiler\".casefold() in row[\"filename:lineno(function)\"].casefold():\n",
    "                profiler_time += row[\"tot_time\"]\n",
    "                profiler_calls += row[\"ncalls\"]\n",
    "                continue\n",
    "            else:\n",
    "                clean_df.loc[len(clean_df)] = row\n",
    "        df_sum.loc[func_index, \"Time\"] -= profiler_time\n",
    "        df_sum.loc[func_index, \"Call_num\"] -= profiler_calls\n",
    "    return df_sum,clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d41b96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00032\n",
      "Parsing file: /data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00032/profiler/fit-training_profile.txt\n",
      "Parsing file: /data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00032/profiler/fit-pretraining_profile.txt\n",
      "/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00030\n",
      "Parsing file: /data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00030/profiler/fit-training_profile.txt\n",
      "Parsing file: /data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00030/profiler/fit-pretraining_profile.txt\n",
      "/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00031\n",
      "Parsing file: /data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00031/profiler/fit-training_profile.txt\n",
      "Parsing file: /data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00031/profiler/fit-pretraining_profile.txt\n",
      "/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00029\n",
      "Parsing file: /data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00029/profiler/fit-training_profile.txt\n",
      "Parsing file: /data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00029/profiler/fit-pretraining_profile.txt\n",
      "/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00027\n",
      "Parsing file: /data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00027/profiler/fit-training_profile.txt\n",
      "Parsing file: /data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00027/profiler/fit-pretraining_profile.txt\n",
      "Skipping test_run_00013!\n",
      "/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00028\n",
      "Parsing file: /data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00028/profiler/fit-training_profile.txt\n",
      "Parsing file: /data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models/test_run_00028/profiler/fit-pretraining_profile.txt\n",
      "Skipping test_run_00014!\n"
     ]
    }
   ],
   "source": [
    "# parse the models dict for profiler data from testrun_synthetic_benchmark.py\n",
    "profile_dict = dict()\n",
    "hyperparameter_names= [\"run_id\",\"data_n_genes\", \"data_n_samples_control\", \"data_n_samples_per_perturbation\", \"batch_size\", \"n_epochs\", \"n_epochs_pretrain_latents\", \"scale_factor\"]\n",
    "hyperparameters = pd.DataFrame(columns=hyperparameter_names)\n",
    "\n",
    "\n",
    "for subdir in MODELS_PATH.iterdir():\n",
    "    if subdir.joinpath(\"profiler\", \"fit-training_profile.txt\").exists():\n",
    "        key = str(subdir.name)\n",
    "        if key in exclude:\n",
    "            print(f\"Skipping {key}!\")\n",
    "            continue\n",
    "        print(subdir)\n",
    "        # get globals of run\n",
    "        globs = pd.read_csv(PLOTS_PATH.joinpath(key, \"globals.csv\"), delimiter=\",\").set_index(\"0\", drop=True).T\n",
    "        available_paras = [n for n in hyperparameter_names if n in globs.columns]\n",
    "        hyperparameters.loc[len(hyperparameters)] = globs[available_paras].iloc[1]\n",
    "\n",
    "        df, df_sum = read_profile(subdir.joinpath(\"profiler\", \"fit-training_profile.txt\"))\n",
    "\n",
    "        # remove profiler traces\n",
    "        df_sum, clean_df = filter_profiler_records(df, df_sum)\n",
    "\n",
    "        profile_dict[key] = dict()\n",
    "        profile_dict[key][\"full_training_profile\"] = clean_df\n",
    "        profile_dict[key][\"training_profile\"] = df_sum\n",
    "        if subdir.joinpath(\"profiler/fit-pretraining_profile.txt\").exists():\n",
    "            df, df_sum = read_profile(subdir.joinpath(\"profiler/fit-pretraining_profile.txt\"))\n",
    "\n",
    "\n",
    "            df_sum, clean_df = filter_profiler_records(df, df_sum)\n",
    "\n",
    "            profile_dict[key][\"full_pretraining_profile\"] = df\n",
    "            profile_dict[key][\"pretraining_profile\"] = df_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81128198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_profile_data(df, df_sum):\n",
    "    full_dtype_converter = {\n",
    "    \"ncalls\": int,\n",
    "    \"tot_time\": float,\n",
    "    \"tot_percall\":float,\n",
    "    \"cum_time\":float,\n",
    "    \"cum_percall\":float,\n",
    "    \"filename:lineno(function)\":str,\n",
    "    \"Class\":str,\n",
    "    \"Function\":str,\n",
    "    \"Call_num\":int,\n",
    "    \"Primitive_Call_num\":int,\n",
    "    \"Time\":float,\n",
    "    #\"Rank\":int,\n",
    "    \"Summary_index\": int\n",
    "}\n",
    "    dtype_converter = {\n",
    "    \"Class\":str,\n",
    "    \"Function\":str,\n",
    "    \"Call_num\":int,\n",
    "    \"Primitive_Call_num\":int,\n",
    "    \"Time\":float,\n",
    "    #\"Rank\":int,\n",
    "}\n",
    "    df_sum[\"Primitive_Call_num\"] = df_sum[\"Primitive_Call_num\"].fillna(0)\n",
    "    df_sum = df_sum.astype(dtype_converter)\n",
    "    df_sum[\"Class_Function\"] = df_sum[\"Class\"] + \"_\" + df_sum[\"Function\"]\n",
    "    df_sum[\"is_callback\"] = df_sum[\"Class\"].apply(lambda x: \"Callback\" in x)\n",
    "\n",
    "    df[\"Primitive_Call_num\"] = df[\"Primitive_Call_num\"].fillna(0)\n",
    "    df = df.astype(full_dtype_converter)\n",
    "    df[\"Class_Function\"] = df[\"Class\"] + \"_\" + df[\"Function\"]\n",
    "    df[\"filename_lineno(function)\"] = df[\"filename:lineno(function)\"]\n",
    "    df.drop(columns=[\"filename:lineno(function)\"])\n",
    "    df[\"Class_Function_etc\"] = df[\"Class_Function\"] + \":\" + df[\"filename_lineno(function)\"]\n",
    "    df[\"is_callback\"] = df[\"Class\"].apply(lambda x: \"Callback\" in x)\n",
    "\n",
    "    return df, df_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e279370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the models dict for profiler data from testrun_synthetic_benchmark.py\n",
    "def fullparse_profiles(\n",
    "        pickle:bool=False,\n",
    "        MODELS_PATH: Path = Path(\"/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/models\"),\n",
    "        ANALYSIS_PATH:Path=Path(\"/data/toulouse/bicycle/notebooks/experiments/bottleneck/data/analysis\"),\n",
    "        hyperparameter_names: list = [\"run_id\",\"data_n_genes\", \"data_n_samples_control\", \"data_n_samples_per_perturbation\", \"batch_size\", \"n_epochs\", \"n_epochs_pretrain_latents\", \"scale_factor\"],\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Standard run to parse all profile output files in MODELS_PATH inside subdirectories with name \"test_run_<run_id>\".\n",
    "\n",
    "    Returns:\n",
    "    tuple(\n",
    "        hyperparameters: pd.DataFrame containing run hyperparameters for each id,\n",
    "        profile_dict: dict() containing DataFrames for all training and pretraining runs\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    profile_dict = dict()\n",
    "    hyperparameters = pd.DataFrame(columns=hyperparameter_names)\n",
    "\n",
    "\n",
    "    for subdir in MODELS_PATH.iterdir():\n",
    "        if subdir.joinpath(\"profiler\", \"fit-training_profile.txt\").exists():\n",
    "            key = str(subdir.name)\n",
    "            if key in exclude:\n",
    "                print(f\"Skipping {key}!\")\n",
    "                continue\n",
    "            print(subdir)\n",
    "        # get globals of run\n",
    "            globs = pd.read_csv(PLOTS_PATH.joinpath(key, \"globals.csv\"), delimiter=\",\").set_index(\"0\", drop=True).T\n",
    "            available_paras = [n for n in hyperparameter_names if n in globs.columns]\n",
    "            hyperparameters.loc[len(hyperparameters)] = globs[available_paras].iloc[1]\n",
    "\n",
    "            df, df_sum = read_profile(subdir.joinpath(\"profiler\", \"fit-training_profile.txt\"))\n",
    "\n",
    "        # remove profiler traces\n",
    "            df_sum, clean_df = filter_profiler_records(df, df_sum)\n",
    "\n",
    "\n",
    "            df, df_sum = process_profile_data(df, df_sum)\n",
    "            if pickle:\n",
    "                clean_df.to_pickle(ANALYSIS_PATH.joinpath(key, \"full_training_profile.gz\"))\n",
    "                df_sum.to_pickle(ANALYSIS_PATH.joinpath(key, \"training_profile.gz\"))\n",
    "            profile_dict[key] = dict()\n",
    "            profile_dict[key][\"full_training_profile\"] = clean_df\n",
    "            profile_dict[key][\"training_profile\"] = df_sum\n",
    "\n",
    "            # check for pretraining profiles\n",
    "            if subdir.joinpath(\"profiler/fit-pretraining_profile.txt\").exists():\n",
    "                df, df_sum = read_profile(subdir.joinpath(\"profiler/fit-pretraining_profile.txt\"))\n",
    "\n",
    "\n",
    "                df_sum, clean_df = filter_profiler_records(df, df_sum)\n",
    "\n",
    "                df, df_sum = process_profile_data(df, df_sum)\n",
    "\n",
    "                if pickle:\n",
    "                    df.to_pickle(ANALYSIS_PATH.joinpath(key, \"full_pretraining_profile.gz\"))\n",
    "                    df_sum.to_pickle(ANALYSIS_PATH.joinpath(key, \"pretraining_profile.gz\"))\n",
    "\n",
    "                profile_dict[key][\"full_pretraining_profile\"] = df\n",
    "                profile_dict[key][\"pretraining_profile\"] = df_sum\n",
    "    if pickle:\n",
    "        hyperparameters.to_csv(ANALYSIS_PATH.joinpath(\"parameters.csv\"))\n",
    "\n",
    "    return hyperparameters, profile_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e88b550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dtype_converter = {\n",
    "    \"ncalls\": int,\n",
    "    \"tot_time\": float,\n",
    "    \"tot_percall\":float,\n",
    "    \"cum_time\":float,\n",
    "    \"cum_percall\":float,\n",
    "    \"filename:lineno(function)\":str,\n",
    "    \"Class\":str,\n",
    "    \"Function\":str,\n",
    "    \"Call_num\":int,\n",
    "    \"Primitive_Call_num\":int,\n",
    "    \"Time\":float,\n",
    "    #\"Rank\":int,\n",
    "    \"Summary_index\": int\n",
    "}\n",
    "dtype_converter = {\n",
    "    \"Class\":str,\n",
    "    \"Function\":str,\n",
    "    \"Call_num\":int,\n",
    "    \"Primitive_Call_num\":int,\n",
    "    \"Time\":float,\n",
    "    #\"Rank\":int,\n",
    "}\n",
    "# type conversion and saving\n",
    "for n, d in profile_dict.items():\n",
    "    for name, df in d.items():\n",
    "        df[\"Primitive_Call_num\"] = df[\"Primitive_Call_num\"].fillna(0)\n",
    "        if name.startswith(\"full\"):\n",
    "            df = df.astype(full_dtype_converter)\n",
    "        else:\n",
    "            df = df.astype(dtype_converter)\n",
    "        df[\"Class_Function\"] = df[\"Class\"] + \"_\" + df[\"Function\"]\n",
    "        if name.startswith(\"full\"):\n",
    "            df[\"filename_lineno(function)\"] = df[\"filename:lineno(function)\"]\n",
    "            df.drop(columns=[\"filename:lineno(function)\"])\n",
    "            df[\"Class_Function_etc\"] = df[\"Class_Function\"] + \":\" + df[\"filename_lineno(function)\"]\n",
    "        df[\"is_callback\"] = df[\"Class\"].apply(lambda x: \"Callback\" in x)\n",
    "\n",
    "        ANALYSIS_PATH.joinpath(n).mkdir(parents=True, exist_ok=True)\n",
    "        df.to_pickle(ANALYSIS_PATH.joinpath(n,f\"{name}.gz\"))\n",
    "        profile_dict[n][name] = df\n",
    "hyperparameters.to_csv(ANALYSIS_PATH.joinpath(\"parameters.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bicycle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
