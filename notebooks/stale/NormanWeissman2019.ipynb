{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6652c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f99ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bicycle.lightning_model import BICYCLE\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from bicycle.dictlogger import DictLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c64eb45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 3141\n"
     ]
    }
   ],
   "source": [
    "SEED = 3141\n",
    "pl.seed_everything(SEED)\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f69a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "N_SAMPLES = 0.5\n",
    "HARD_THRESHOLD = True\n",
    "num_downstream_genes = 5\n",
    "num_perturbation_genes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d06f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cpu\")\n",
    "if CUDA:\n",
    "    GPU_DEVICE = 0\n",
    "    torch.cuda.set_device(GPU_DEVICE)\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "DATA_PATH = Path(\"/data/m015k/data/bicycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb24d233-9c56-4d65-8c8c-fa3636eaccb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(DATA_PATH / \"NormanWeissman2019_filtered.h5ad\")\n",
    "\n",
    "# Remove all genes with 0 variance\n",
    "adata = adata[:, adata.X.todense().var(axis=0) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e445ff-47a1-43ea-b0c5-296b2c6da864",
   "metadata": {},
   "source": [
    "def cdf(x):\n",
    "    # Calculate and plot cumulative distribution function from 1D-samples\n",
    "    x, y = sorted(x), np.arange(len(x)) / len(x)\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b78d36-6911-41b1-b12d-0a6973e01f0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "gene_set = adata.obs.perturbation.unique()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0338118e-2c13-4542-bcad-826f6887f156",
   "metadata": {},
   "source": [
    "var_names = adata.var_names.to_list()\n",
    "\n",
    "for gene in gene_set:\n",
    "    if gene in var_names:\n",
    "        plt.figure()\n",
    "        plt.title(gene)\n",
    "        x_obs, y_obs = cdf(\n",
    "            np.asarray(\n",
    "                adata[adata.obs[\"perturbation\"] == \"control\", gene].X.todense()\n",
    "            ).squeeze()\n",
    "        )\n",
    "        plt.plot(x_obs, y_obs, label=\"unperturbed: %d cells\" % len(x_obs))\n",
    "\n",
    "        x_obs, y_obs = cdf(\n",
    "            np.asarray(\n",
    "                adata[adata.obs[\"perturbation\"] == gene, gene].X.todense()\n",
    "            ).squeeze()\n",
    "        )\n",
    "        plt.plot(x_obs, y_obs, label=\"perturbed: %d cells\" % len(x_obs))\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "157bf6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guide_id</th>\n",
       "      <th>read_count</th>\n",
       "      <th>UMI_count</th>\n",
       "      <th>coverage</th>\n",
       "      <th>gemgroup</th>\n",
       "      <th>good_coverage</th>\n",
       "      <th>number_of_cells</th>\n",
       "      <th>tissue_type</th>\n",
       "      <th>cell_line</th>\n",
       "      <th>cancer</th>\n",
       "      <th>disease</th>\n",
       "      <th>perturbation_type</th>\n",
       "      <th>celltype</th>\n",
       "      <th>organism</th>\n",
       "      <th>perturbation</th>\n",
       "      <th>nperts</th>\n",
       "      <th>ngenes</th>\n",
       "      <th>ncounts</th>\n",
       "      <th>percent_mito</th>\n",
       "      <th>percent_ribo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TTGAACGAGACTCGGA</th>\n",
       "      <td>ARID1A_NegCtrl0;ARID1A_NegCtrl0</td>\n",
       "      <td>28684</td>\n",
       "      <td>1809</td>\n",
       "      <td>15.856274</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cell_line</td>\n",
       "      <td>K562</td>\n",
       "      <td>True</td>\n",
       "      <td>chronic myelogenous leukemia</td>\n",
       "      <td>CRISPR</td>\n",
       "      <td>lymphoblasts</td>\n",
       "      <td>human</td>\n",
       "      <td>ARID1A</td>\n",
       "      <td>1</td>\n",
       "      <td>3079</td>\n",
       "      <td>15097.0</td>\n",
       "      <td>5.815725</td>\n",
       "      <td>33.569583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGTTGGGGTGTTTGTG</th>\n",
       "      <td>BCORL1_NegCtrl0;BCORL1_NegCtrl0</td>\n",
       "      <td>18367</td>\n",
       "      <td>896</td>\n",
       "      <td>20.498884</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cell_line</td>\n",
       "      <td>K562</td>\n",
       "      <td>True</td>\n",
       "      <td>chronic myelogenous leukemia</td>\n",
       "      <td>CRISPR</td>\n",
       "      <td>lymphoblasts</td>\n",
       "      <td>human</td>\n",
       "      <td>BCORL1</td>\n",
       "      <td>1</td>\n",
       "      <td>2100</td>\n",
       "      <td>8551.0</td>\n",
       "      <td>4.104783</td>\n",
       "      <td>45.842592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAACCTAAGTGTTAGA</th>\n",
       "      <td>FOSB_NegCtrl0;FOSB_NegCtrl0</td>\n",
       "      <td>16296</td>\n",
       "      <td>664</td>\n",
       "      <td>24.542169</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cell_line</td>\n",
       "      <td>K562</td>\n",
       "      <td>True</td>\n",
       "      <td>chronic myelogenous leukemia</td>\n",
       "      <td>CRISPR</td>\n",
       "      <td>lymphoblasts</td>\n",
       "      <td>human</td>\n",
       "      <td>FOSB</td>\n",
       "      <td>1</td>\n",
       "      <td>2772</td>\n",
       "      <td>10999.0</td>\n",
       "      <td>5.655060</td>\n",
       "      <td>17.801618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCTTCCCTCCGTCATC</th>\n",
       "      <td>SET_KLF1;SET_KLF1</td>\n",
       "      <td>16262</td>\n",
       "      <td>850</td>\n",
       "      <td>19.131765</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cell_line</td>\n",
       "      <td>K562</td>\n",
       "      <td>True</td>\n",
       "      <td>chronic myelogenous leukemia</td>\n",
       "      <td>CRISPR</td>\n",
       "      <td>lymphoblasts</td>\n",
       "      <td>human</td>\n",
       "      <td>SET_KLF1</td>\n",
       "      <td>2</td>\n",
       "      <td>5385</td>\n",
       "      <td>38454.0</td>\n",
       "      <td>4.335050</td>\n",
       "      <td>38.165080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCAATCTGTCTTTCAT</th>\n",
       "      <td>OSR2_NegCtrl0;OSR2_NegCtrl0</td>\n",
       "      <td>16057</td>\n",
       "      <td>1067</td>\n",
       "      <td>15.048735</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>cell_line</td>\n",
       "      <td>K562</td>\n",
       "      <td>True</td>\n",
       "      <td>chronic myelogenous leukemia</td>\n",
       "      <td>CRISPR</td>\n",
       "      <td>lymphoblasts</td>\n",
       "      <td>human</td>\n",
       "      <td>OSR2</td>\n",
       "      <td>1</td>\n",
       "      <td>4869</td>\n",
       "      <td>27926.0</td>\n",
       "      <td>5.084867</td>\n",
       "      <td>32.317554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         guide_id  read_count  UMI_count  \\\n",
       "TTGAACGAGACTCGGA  ARID1A_NegCtrl0;ARID1A_NegCtrl0       28684       1809   \n",
       "CGTTGGGGTGTTTGTG  BCORL1_NegCtrl0;BCORL1_NegCtrl0       18367        896   \n",
       "GAACCTAAGTGTTAGA      FOSB_NegCtrl0;FOSB_NegCtrl0       16296        664   \n",
       "CCTTCCCTCCGTCATC                SET_KLF1;SET_KLF1       16262        850   \n",
       "TCAATCTGTCTTTCAT      OSR2_NegCtrl0;OSR2_NegCtrl0       16057       1067   \n",
       "\n",
       "                   coverage  gemgroup  good_coverage  number_of_cells  \\\n",
       "TTGAACGAGACTCGGA  15.856274         2           True                1   \n",
       "CGTTGGGGTGTTTGTG  20.498884         7           True                1   \n",
       "GAACCTAAGTGTTAGA  24.542169         6           True                1   \n",
       "CCTTCCCTCCGTCATC  19.131765         4           True                1   \n",
       "TCAATCTGTCTTTCAT  15.048735         2           True                2   \n",
       "\n",
       "                 tissue_type cell_line  cancer                       disease  \\\n",
       "TTGAACGAGACTCGGA   cell_line      K562    True  chronic myelogenous leukemia   \n",
       "CGTTGGGGTGTTTGTG   cell_line      K562    True  chronic myelogenous leukemia   \n",
       "GAACCTAAGTGTTAGA   cell_line      K562    True  chronic myelogenous leukemia   \n",
       "CCTTCCCTCCGTCATC   cell_line      K562    True  chronic myelogenous leukemia   \n",
       "TCAATCTGTCTTTCAT   cell_line      K562    True  chronic myelogenous leukemia   \n",
       "\n",
       "                 perturbation_type      celltype organism perturbation  \\\n",
       "TTGAACGAGACTCGGA            CRISPR  lymphoblasts    human       ARID1A   \n",
       "CGTTGGGGTGTTTGTG            CRISPR  lymphoblasts    human       BCORL1   \n",
       "GAACCTAAGTGTTAGA            CRISPR  lymphoblasts    human         FOSB   \n",
       "CCTTCCCTCCGTCATC            CRISPR  lymphoblasts    human     SET_KLF1   \n",
       "TCAATCTGTCTTTCAT            CRISPR  lymphoblasts    human         OSR2   \n",
       "\n",
       "                  nperts  ngenes  ncounts  percent_mito  percent_ribo  \n",
       "TTGAACGAGACTCGGA       1    3079  15097.0      5.815725     33.569583  \n",
       "CGTTGGGGTGTTTGTG       1    2100   8551.0      4.104783     45.842592  \n",
       "GAACCTAAGTGTTAGA       1    2772  10999.0      5.655060     17.801618  \n",
       "CCTTCCCTCCGTCATC       2    5385  38454.0      4.335050     38.165080  \n",
       "TCAATCTGTCTTTCAT       1    4869  27926.0      5.084867     32.317554  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ba155bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample rows randomly\n",
    "if N_SAMPLES:\n",
    "    if N_SAMPLES < 1:\n",
    "        # Subsample adata to N per cent of samples\n",
    "        adata = adata[\n",
    "            np.random.choice(\n",
    "                adata.shape[0], int(N_SAMPLES * adata.shape[0]), replace=False\n",
    "            ),\n",
    "            :,\n",
    "        ]\n",
    "    else:\n",
    "        # Subsample adata to N samples\n",
    "        adata = adata[np.random.choice(adata.shape[0], N_SAMPLES, replace=False), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f662c4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Gene MMP13 not found in data\n",
      "✓ Gene TGFBR2 found in data\n"
     ]
    }
   ],
   "source": [
    "# Genes that must be included\n",
    "prio_downstream_genes = [\"MMP13\"]\n",
    "prio_perturbation_genes = [\"TGFBR2\"]\n",
    "\n",
    "# Print if genes are found or not in data\n",
    "for gene in prio_downstream_genes:\n",
    "    if gene in adata.var.index:\n",
    "        print(f\"✓ Gene {gene} found in data\")\n",
    "    else:\n",
    "        print(f\"✗ Gene {gene} not found in data\")\n",
    "        prio_downstream_genes.remove(gene)\n",
    "\n",
    "for gene in prio_perturbation_genes:\n",
    "    if gene in adata.obs.perturbation.unique():\n",
    "        print(f\"✓ Gene {gene} found in data\")\n",
    "    else:\n",
    "        print(f\"✗ Gene {gene} not found in data\")\n",
    "        # Remove gene from prio_perturbation_genes\n",
    "        prio_perturbation_genes.remove(gene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d1570",
   "metadata": {},
   "source": [
    "results = prepare_dataset(\n",
    "    adata,\n",
    "    p_val=0.2,\n",
    "    p_test=0.2,\n",
    "    min_perturbed_cells=0,\n",
    "    use_clusters_for_holdout=True,\n",
    "    stratify_regimes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3518354f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of single perturbations: 102\n",
      "['MAP2K6', 'CBL', 'FOXA3', 'AHR', 'CDKN1C', 'SGK1', 'MAP2K3', 'SAMD1', 'ATL1', 'PRTG', 'ZC3HAV1', 'CITED1', 'ZNF318', 'CLDN6', 'COL1A1', 'NIT1', 'GLB1L2', 'CELF2', 'MEIS1', 'IRF1', 'STIL', 'SLC38A2', 'PTPN12', 'UBASH3A', 'ARRDC3', 'HES7', 'LHX1', 'HK2', 'TSC22D1', 'RREB1', 'BPGM', 'BCL2L11', 'ZBTB25', 'RHOXF2', 'MAPK1', 'CKS1B', 'TP73', 'TMSB4X', 'HOXC13', 'KIF2C', 'HOXB9', 'OSR2', 'DUSP9', 'PTPN1', 'JUN', 'FOXO4', 'POU3F2', 'UBASH3B', 'PLK4', 'CDKN1A', 'ARID1A', 'ELMSAN1', 'SLC4A1', 'CEBPA', 'ZBTB10', 'MAP4K3', 'LYL1', 'ETS2', 'CDKN1B', 'IKZF3', 'FEV', 'MIDN', 'SLC6A9', 'BCORL1', 'TGFBR2', 'SNAI1', 'CNN1', 'MAP7D1', 'KIF18B', 'FOXA1', 'CBFA2T3', 'DLX2', 'KMT2A', 'MAP4K5', 'CEBPE', 'TBX3', 'FOXL2', 'KLF1', 'COL2A1', 'SPI1', 'MAML2', 'TBX2', 'CNNM4', 'S1PR2', 'FOXF1', 'FOSB', 'EGR1', 'PTPN13', 'PTPN9', 'ISL2', 'BAK1', 'CSRNP1', 'ZBTB1', 'RUNX1T1', 'CEBPB', 'IGDCC3', 'HOXA13', 'NCL', 'PRDM1', 'SET', 'IER5L', 'HNF4A']\n"
     ]
    }
   ],
   "source": [
    "# Find all genes that have been perturbed at least once\n",
    "perturbed_genes = adata.obs.perturbation.unique()\n",
    "perturbed_genes = [\n",
    "    x for x in perturbed_genes if (not \"_\" in x) & (x in adata.var.index)\n",
    "]\n",
    "perturbation_genes = list(set(perturbed_genes))\n",
    "print(f\"Number of single perturbations: {len(perturbation_genes)}\")\n",
    "print(perturbation_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19378e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You’re trying to run this on 25038 dimensions of `.X`, if you really want this, set `use_rep='X'`.\n",
      "         Falling back to preprocessing with `sc.pp.pca` and default params.\n",
      "Lenght of cluster: 2\n",
      "Lenght of cluster: 24\n",
      "Lenght of cluster: 40\n",
      "Lenght of cluster: 22\n",
      "Lenght of cluster: 14\n"
     ]
    }
   ],
   "source": [
    "# CLUSTER perturbations\n",
    "import math\n",
    "\n",
    "pert_name = \"perturbation\"\n",
    "intervened_variables = perturbation_genes\n",
    "\n",
    "adata_perturbed = adata[adata.obs[pert_name].isin(intervened_variables)]\n",
    "sc.tl.dendrogram(adata_perturbed, groupby=pert_name)\n",
    "clusters = list()\n",
    "\n",
    "# Individual leave colors\n",
    "dp = \"dendrogram_\" + pert_name\n",
    "di = \"dendrogram_info\"\n",
    "leave_colors = adata_perturbed.uns[dp][di][\"leaves_color_list\"]\n",
    "names = adata_perturbed.uns[dp][di][\"ivl\"]\n",
    "\n",
    "for leave_color in set(leave_colors):\n",
    "    cluster = [names[i] for i, lc in enumerate(leave_colors) if lc == leave_color]\n",
    "    clusters.append(cluster)\n",
    "\n",
    "for c in clusters:\n",
    "    print(f\"Lenght of cluster: {len(c)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "661fa234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cluster of prio_perturbation_genes\n",
    "perturbation_cluster = []\n",
    "for idx, c in enumerate(clusters):\n",
    "    if any([x in c for x in prio_perturbation_genes]):\n",
    "        perturbation_cluster.extend(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "249c4ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: selected more genes than initially planned\n",
      "- Using hard threshold\n",
      "['CNN1', 'PTPN12', 'SET', 'CSRNP1', 'MAP2K3', 'MAP2K6', 'TGFBR2', 'ELMSAN1', 'BAK1', 'MAML2', 'control']\n"
     ]
    }
   ],
   "source": [
    "# Select a subset of genes, but only those that are in the data\n",
    "selected_perturbed_genes = perturbation_cluster\n",
    "all_perturbation_wo_pairs = [\n",
    "    x\n",
    "    for x in adata.obs.perturbation.to_list()\n",
    "    if (not \"_\" in x) & (x in adata.var.index)\n",
    "]\n",
    "if len(selected_perturbed_genes) > num_perturbation_genes:\n",
    "    print(\"Warning: selected more genes than initially planned\")\n",
    "    if HARD_THRESHOLD:\n",
    "        print(\"- Using hard threshold\")\n",
    "        selected_perturbed_genes = selected_perturbed_genes[:num_perturbation_genes]\n",
    "else:\n",
    "    not_included_genes = list(\n",
    "        set(all_perturbation_wo_pairs) - set(selected_perturbed_genes)\n",
    "    )\n",
    "    selected_perturbed_genes = (\n",
    "        selected_perturbed_genes\n",
    "        + not_included_genes[: (num_perturbation_genes - len(selected_perturbed_genes))]\n",
    "    )\n",
    "selected_perturbed_genes = selected_perturbed_genes + [\"control\"]\n",
    "print(selected_perturbed_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1df80f",
   "metadata": {},
   "source": [
    "selected_perturbed_genes_wo_control = [\n",
    "    x for x in selected_perturbed_genes if x != \"control\"\n",
    "]\n",
    "np.corrcoef(\n",
    "    adata[:, selected_perturbed_genes_wo_control].X.todense(), rowvar=False\n",
    ")[: len(selected_perturbed_genes_wo_control), -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae5de4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_perturbed_genes_wo_control = [\n",
    "    x for x in selected_perturbed_genes if x != \"control\"\n",
    "]\n",
    "\n",
    "# Find genes that are highly correlated with genes in selected_perturbed_genes\n",
    "x1 = adata[:, selected_perturbed_genes_wo_control].X.todense()\n",
    "names = [x for x in adata.var.index if x not in selected_perturbed_genes_wo_control]\n",
    "x2 = adata[:, names].X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62dbae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/numpy/lib/function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# Subsample both dfs\n",
    "n_samples = 1000\n",
    "idx = np.random.choice(x1.shape[0], 1000, replace=False)\n",
    "x1 = x1[idx, :]\n",
    "x2 = x2[idx, :]\n",
    "# Compute column wise correlation between x1 and x2\n",
    "corr = np.corrcoef(x1, x2, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8628655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.abs(\n",
    "    corr[\n",
    "        len(selected_perturbed_genes_wo_control) :,\n",
    "        : len(selected_perturbed_genes_wo_control),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cef971",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(c, cmap=\"vlag\", center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aefb0927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top row indices: ['LL09NC01-139C3.1', 'FUT7', 'RP11-216L13.17', 'LCNL1', 'ENTPD2']\n"
     ]
    }
   ],
   "source": [
    "def top_indices(matrix):\n",
    "    flat_indices = np.argsort(matrix.ravel())[::-1]\n",
    "    row_indices, _ = np.unravel_index(flat_indices, matrix.shape)\n",
    "    return row_indices\n",
    "\n",
    "\n",
    "top_row_indices = list(top_indices(c, num_downstream_genes))\n",
    "# Selct first num_downstream_genes different genes\n",
    "top_genes = []\n",
    "for k in top_row_indices:\n",
    "    if not names[k] in top_genes:\n",
    "        top_genes.append(names[k])\n",
    "    if len(top_genes) == num_downstream_genes:\n",
    "        break\n",
    "print(\"Top row indices:\", top_genes)\n",
    "\n",
    "prio_downstream_genes = list(set(prio_downstream_genes) | set(top_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "171f710b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MAP2K6', 'FUT7', 'BAK1', 'ELMSAN1', 'LL09NC01-139C3.1', 'CSRNP1', 'TGFBR2', 'LCNL1', 'MAP2K3', 'ENTPD2', 'PTPN12', 'CNN1', 'MAML2', 'RP11-216L13.17', 'SET']\n"
     ]
    }
   ],
   "source": [
    "# All genes in study we care about\n",
    "all_gene_in_graph = list(\n",
    "    (set(selected_perturbed_genes) | set(prio_downstream_genes)) - set([\"control\"])\n",
    ")\n",
    "print(all_gene_in_graph)\n",
    "assert any([x for x in selected_perturbed_genes if x not in all_gene_in_graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a300a74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55722, 25038)\n",
      "(9868, 25038)\n",
      "Count matrix shape: (9868, 15)\n"
     ]
    }
   ],
   "source": [
    "samples = adata\n",
    "print(samples.shape)\n",
    "\n",
    "# Subset obs data to only include perturbation we want to use\n",
    "samples = adata[adata.obs.perturbation.isin(selected_perturbed_genes), :]\n",
    "print(samples.shape)\n",
    "\n",
    "# Optional: subset genes\n",
    "samples = samples[:, samples.var.index.isin(all_gene_in_graph)]\n",
    "print(f\"Count matrix shape: {samples.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c06fcbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'control': 0,\n",
       " 'MAP2K6': 1,\n",
       " 'FUT7': None,\n",
       " 'BAK1': 2,\n",
       " 'ELMSAN1': 3,\n",
       " 'LL09NC01-139C3.1': None,\n",
       " 'CSRNP1': 4,\n",
       " 'TGFBR2': 5,\n",
       " 'LCNL1': None,\n",
       " 'MAP2K3': 6,\n",
       " 'ENTPD2': None,\n",
       " 'PTPN12': 7,\n",
       " 'CNN1': 8,\n",
       " 'MAML2': 9,\n",
       " 'RP11-216L13.17': None,\n",
       " 'SET': 10}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping between gene and context:\n",
    "gene_to_intervention_idx = {\"control\": 0}\n",
    "c = 1\n",
    "for k in all_gene_in_graph:\n",
    "    if (k in selected_perturbed_genes) & (k != \"control\"):\n",
    "        gene_to_intervention_idx[k] = c\n",
    "        c += 1\n",
    "    else:\n",
    "        gene_to_intervention_idx[k] = None\n",
    "\n",
    "gene_to_intervention_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5925d5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP2K6': 0,\n",
       " 'FUT7': 1,\n",
       " 'BAK1': 2,\n",
       " 'ELMSAN1': 3,\n",
       " 'LL09NC01-139C3.1': 4,\n",
       " 'CSRNP1': 5,\n",
       " 'TGFBR2': 6,\n",
       " 'LCNL1': 7,\n",
       " 'MAP2K3': 8,\n",
       " 'ENTPD2': 9,\n",
       " 'PTPN12': 10,\n",
       " 'CNN1': 11,\n",
       " 'MAML2': 12,\n",
       " 'RP11-216L13.17': 13,\n",
       " 'SET': 14}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_gene_in_graph_map_to_idx = {k: i for i, k in enumerate(all_gene_in_graph)}\n",
    "all_gene_in_graph_map_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81fef65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_interv.shape=torch.Size([15, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Genes x regimes matrices, which indexes which genes are intervened in\n",
    "# which context\n",
    "n_contexts = len(selected_perturbed_genes)  # including control\n",
    "gt_interv = torch.zeros((len(gene_to_intervention_idx) - 1, n_contexts), device=device)\n",
    "for n, name in enumerate(all_gene_in_graph):\n",
    "    if gene_to_intervention_idx.get(name):\n",
    "        gt_interv[n, gene_to_intervention_idx[name]] = 1\n",
    "print(f\"{gt_interv.shape=}\")\n",
    "gt_interv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "671cea80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6008.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,  421.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,  742.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,  484.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,  228.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,  332.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,  279.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,  223.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,  372.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         324.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         455.]),\n",
       " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ,\n",
       "         1.1,  1.2,  1.3,  1.4,  1.5,  1.6,  1.7,  1.8,  1.9,  2. ,  2.1,\n",
       "         2.2,  2.3,  2.4,  2.5,  2.6,  2.7,  2.8,  2.9,  3. ,  3.1,  3.2,\n",
       "         3.3,  3.4,  3.5,  3.6,  3.7,  3.8,  3.9,  4. ,  4.1,  4.2,  4.3,\n",
       "         4.4,  4.5,  4.6,  4.7,  4.8,  4.9,  5. ,  5.1,  5.2,  5.3,  5.4,\n",
       "         5.5,  5.6,  5.7,  5.8,  5.9,  6. ,  6.1,  6.2,  6.3,  6.4,  6.5,\n",
       "         6.6,  6.7,  6.8,  6.9,  7. ,  7.1,  7.2,  7.3,  7.4,  7.5,  7.6,\n",
       "         7.7,  7.8,  7.9,  8. ,  8.1,  8.2,  8.3,  8.4,  8.5,  8.6,  8.7,\n",
       "         8.8,  8.9,  9. ,  9.1,  9.2,  9.3,  9.4,  9.5,  9.6,  9.7,  9.8,\n",
       "         9.9, 10. ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim_regime = torch.tensor(\n",
    "    [x for x in samples.obs.perturbation.map(gene_to_intervention_idx).values]\n",
    ").long()\n",
    "# intervened_variables = gt_interv[:, sim_regime].transpose(0, 1)\n",
    "plt.hist(sim_regime.cpu().numpy(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5012d73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_normalized.shape=torch.Size([9868, 15])\n"
     ]
    }
   ],
   "source": [
    "samples_normalized = torch.tensor(samples.X.todense())\n",
    "print(f\"{samples_normalized.shape=}\")\n",
    "\n",
    "# Log x+1 transform\n",
    "samples_normalized = torch.log(samples_normalized + 1)\n",
    "# z-score\n",
    "samples_normalized = (\n",
    "    samples_normalized - samples_normalized.mean(dim=0)\n",
    ") / samples_normalized.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d17f8f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.0000e+01, 0.0000e+00, 2.3000e+01, 3.9000e+01, 0.0000e+00,\n",
       "        1.5400e+02, 1.4000e+02, 7.1500e+02, 5.7580e+03, 5.3437e+04,\n",
       "        5.1565e+04, 5.2980e+03, 4.4300e+03, 2.2530e+03, 2.3830e+03,\n",
       "        3.0500e+02, 9.0200e+02, 1.7000e+02, 5.2000e+01, 5.2000e+01,\n",
       "        7.4000e+01, 2.3600e+02, 1.6900e+02, 5.0000e+00, 6.0000e+00,\n",
       "        3.0000e+00, 2.0000e+00, 1.2000e+01, 2.0000e+00, 0.0000e+00,\n",
       "        1.5000e+01, 0.0000e+00, 7.0000e+00, 0.0000e+00, 4.5000e+01,\n",
       "        4.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        5.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0000e+00]),\n",
       " array([-5.68600416, -5.13258076, -4.57915783, -4.02573442, -3.47231126,\n",
       "        -2.91888809, -2.36546469, -1.81204152, -1.25861835, -0.70519513,\n",
       "        -0.15177187,  0.40165135,  0.95507455,  1.50849783,  2.06192112,\n",
       "         2.61534429,  3.16876745,  3.72219062,  4.27561378,  4.82903719,\n",
       "         5.38246059,  5.93588352,  6.48930693,  7.04272985,  7.59615326,\n",
       "         8.14957619,  8.70300007,  9.256423  ,  9.80984592, 10.36326981,\n",
       "        10.91669273, 11.47011566, 12.02353954, 12.57696247, 13.1303854 ,\n",
       "        13.68380928, 14.23723221, 14.79065514, 15.34407806, 15.89750195,\n",
       "        16.45092583, 17.00434875, 17.55777168, 18.11119461, 18.66461754,\n",
       "        19.21804047, 19.77146339, 20.32488823, 20.87831116, 21.43173409,\n",
       "        21.98515701, 22.53857994, 23.09200287, 23.6454277 , 24.19885063,\n",
       "        24.75227356, 25.30569649, 25.85911942, 26.41254234, 26.96596718,\n",
       "        27.51939011, 28.07281303, 28.62623596, 29.17965889, 29.73308182,\n",
       "        30.28650475, 30.83992958, 31.39335251, 31.94677544, 32.50019836,\n",
       "        33.0536232 , 33.60704422, 34.16046906, 34.71389008, 35.26731491,\n",
       "        35.82073975, 36.37416077, 36.9275856 , 37.48100662, 38.03443146,\n",
       "        38.58785248, 39.14127731, 39.69470215, 40.24812317, 40.801548  ,\n",
       "        41.35496902, 41.90839386, 42.46181488, 43.01523972, 43.56866455,\n",
       "        44.12208557, 44.67551041, 45.22893143, 45.78235626, 46.3357811 ,\n",
       "        46.88920212, 47.44262695, 47.99604797, 48.54947281, 49.10289383,\n",
       "        49.65631866]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(samples_normalized.flatten().cpu().numpy(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d0a3093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset size: samples_normalized.shape=torch.Size([9868, 15])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final dataset size: {samples_normalized.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53ad47e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_interventions = torch.tensor(\n",
    "    samples.obs.perturbation.map(gene_to_intervention_idx).values\n",
    ").long()\n",
    "samples_interventions = samples_interventions.to(torch.int64)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(\n",
    "    samples_normalized,\n",
    "    samples_interventions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f492b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Sampling for train and val\n",
    "train_idx, validation_idx = train_test_split(\n",
    "    np.arange(len(samples_normalized)),\n",
    "    test_size=0.25,\n",
    "    random_state=SEED,\n",
    "    shuffle=True,\n",
    "    stratify=samples_interventions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3b8fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset dataset for train and val\n",
    "train_dataset = Subset(train_data, train_idx)\n",
    "validation_dataset = Subset(train_data, validation_idx)\n",
    "\n",
    "# Dataloader for train and val\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "validation_loader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "424f2ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale Lyapunov: 1\n",
      "Scale spectral loss: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:71: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━┳━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━╇━━━━━━╇━━━━━━━━┩\n",
       "└───┴──────┴──────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━┳━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━╇━━━━━━╇━━━━━━━━┩\n",
       "└───┴──────┴──────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 780                                                                                              \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 225                                                                                          \n",
       "<span style=\"font-weight: bold\">Total params</span>: 1.0 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 780                                                                                              \n",
       "\u001b[1mNon-trainable params\u001b[0m: 225                                                                                          \n",
       "\u001b[1mTotal params\u001b[0m: 1.0 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82699114c30c4395bf38e1fc354c1280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Expected value argument (Tensor of shape (512, 15)) to be within the support (IndependentConstraint(Real(), 1)) of the distribution LowRankMultivariateNormal(loc: torch.Size([512, 15]), cov_factor: torch.Size([512, 15, 2]), cov_diag: torch.Size([512, 15])), but found invalid values:\ntensor([[-0.1248, -0.2646,  1.0731,  ..., -0.3254, -0.0698, -0.3528],\n        [-0.1248,  3.3279, -0.6171,  ..., -0.3254, -0.0698, -0.3528],\n        [-0.1248, -0.2646, -0.6171,  ..., -0.3254, -0.0698, -0.3528],\n        ...,\n        [-0.1248, -0.2646, -0.6171,  ...,  2.4624, -0.0698, -0.3528],\n        [-0.1248, -0.2646,  2.0618,  ..., -0.3254, -0.0698, -0.3528],\n        [ 6.9879, -0.2646, -0.6171,  ..., -0.3254, -0.0698, -0.3528]],\n       device='cuda:0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 60\u001b[0m\n\u001b[1;32m     45\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(\n\u001b[1;32m     46\u001b[0m     max_epochs\u001b[39m=\u001b[39mn_epochs,\n\u001b[1;32m     47\u001b[0m     accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(device)\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m=\u001b[39m[RichProgressBar()],\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     59\u001b[0m \u001b[39m# try:\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, train_loader)\n\u001b[1;32m     62\u001b[0m \u001b[39m# Plot training curve\u001b[39;00m\n\u001b[1;32m     63\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m, \u001b[39m5\u001b[39m))\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[0;32m--> 532\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    533\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    534\u001b[0m )\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m    562\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    566\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    567\u001b[0m     ckpt_path,\n\u001b[1;32m    568\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    570\u001b[0m )\n\u001b[0;32m--> 571\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    982\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1022\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1023\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1024\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected state \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 202\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance()\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:355\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(combined_loader)\n\u001b[1;32m    354\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:133\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(data_fetcher)\n\u001b[1;32m    134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    135\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:219\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    217\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    218\u001b[0m         \u001b[39m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mautomatic_optimization\u001b[39m.\u001b[39;49mrun(trainer\u001b[39m.\u001b[39;49moptimizers[\u001b[39m0\u001b[39;49m], kwargs)\n\u001b[1;32m    220\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_optimization\u001b[39m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:188\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         closure()\n\u001b[1;32m    183\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step(kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mbatch_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m), closure)\n\u001b[1;32m    190\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[1;32m    191\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:266\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_ready()\n\u001b[1;32m    265\u001b[0m \u001b[39m# model hook\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m call\u001b[39m.\u001b[39;49m_call_lightning_module_hook(\n\u001b[1;32m    267\u001b[0m     trainer,\n\u001b[1;32m    268\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moptimizer_step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    269\u001b[0m     trainer\u001b[39m.\u001b[39;49mcurrent_epoch,\n\u001b[1;32m    270\u001b[0m     batch_idx,\n\u001b[1;32m    271\u001b[0m     optimizer,\n\u001b[1;32m    272\u001b[0m     train_step_and_backward_closure,\n\u001b[1;32m    273\u001b[0m )\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    276\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:145\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m    144\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 145\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    147\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    148\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/core/module.py:1270\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[1;32m   1233\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1234\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1239\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer`\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[39m    calls the optimizer.\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[39m                    pg[\"lr\"] = lr_scale * self.learning_rate\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1270\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49moptimizer_closure)\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py:161\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    160\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy\u001b[39m.\u001b[39;49moptimizer_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_after_step()\n\u001b[1;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:231\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule)\n\u001b[0;32m--> 231\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49moptimizer_step(optimizer, model\u001b[39m=\u001b[39;49mmodel, closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:116\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m closure \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 116\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/torch/optim/adam.py:121\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[0;32m--> 121\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[1;32m    124\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:103\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_closure\u001b[39m(\n\u001b[1;32m     92\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     93\u001b[0m     model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m     optimizer: Optimizer,\n\u001b[1;32m     95\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m     96\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     97\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[1;32m    100\u001b[0m \u001b[39m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     closure_result \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:142\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclosure(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:128\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39menable_grad()\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 128\u001b[0m     step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_fn()\n\u001b[1;32m    130\u001b[0m     \u001b[39mif\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarning_cache\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:315\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m trainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\n\u001b[1;32m    314\u001b[0m \u001b[39m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m training_step_output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, \u001b[39m\"\u001b[39;49m\u001b[39mtraining_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    316\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_training_step()\n\u001b[1;32m    318\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_result_cls\u001b[39m.\u001b[39mfrom_training_step_output(training_step_output, trainer\u001b[39m.\u001b[39maccumulate_grad_batches)\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:293\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    295\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    296\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:380\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mtrain_step_context():\n\u001b[1;32m    379\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, TrainingStep)\n\u001b[0;32m--> 380\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtraining_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/code/bicycle/src/bicycle/lightning_model.py:224\u001b[0m, in \u001b[0;36mBICYCLE.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdistributions\u001b[39m.\u001b[39mMultivariateNormal(\n\u001b[1;32m    221\u001b[0m         x_bar, covariance_matrix\u001b[39m=\u001b[39momegas_broadcasted\n\u001b[1;32m    222\u001b[0m     )\n\u001b[0;32m--> 224\u001b[0m log_likelihood \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39;49mlog_prob(samples)\n\u001b[1;32m    226\u001b[0m \u001b[39m# Add L1 Penalty on Beta for sparsity\u001b[39;00m\n\u001b[1;32m    227\u001b[0m l1_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mabs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta)\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/torch/distributions/lowrank_multivariate_normal.py:188\u001b[0m, in \u001b[0;36mLowRankMultivariateNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_prob\u001b[39m(\u001b[39mself\u001b[39m, value):\n\u001b[1;32m    187\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_args:\n\u001b[0;32m--> 188\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_sample(value)\n\u001b[1;32m    189\u001b[0m     diff \u001b[39m=\u001b[39m value \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc\n\u001b[1;32m    190\u001b[0m     M \u001b[39m=\u001b[39m _batch_lowrank_mahalanobis(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unbroadcasted_cov_factor,\n\u001b[1;32m    191\u001b[0m                                    \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unbroadcasted_cov_diag,\n\u001b[1;32m    192\u001b[0m                                    diff,\n\u001b[1;32m    193\u001b[0m                                    \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_capacitance_tril)\n",
      "File \u001b[0;32m/data/m015k/miniconda3/envs/bi/lib/python3.11/site-packages/torch/distributions/distribution.py:300\u001b[0m, in \u001b[0;36mDistribution._validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    298\u001b[0m valid \u001b[39m=\u001b[39m support\u001b[39m.\u001b[39mcheck(value)\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid\u001b[39m.\u001b[39mall():\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected value argument \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(value\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mto be within the support (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(support)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof the distribution \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut found invalid values:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected value argument (Tensor of shape (512, 15)) to be within the support (IndependentConstraint(Real(), 1)) of the distribution LowRankMultivariateNormal(loc: torch.Size([512, 15]), cov_factor: torch.Size([512, 15, 2]), cov_diag: torch.Size([512, 15])), but found invalid values:\ntensor([[-0.1248, -0.2646,  1.0731,  ..., -0.3254, -0.0698, -0.3528],\n        [-0.1248,  3.3279, -0.6171,  ..., -0.3254, -0.0698, -0.3528],\n        [-0.1248, -0.2646, -0.6171,  ..., -0.3254, -0.0698, -0.3528],\n        ...,\n        [-0.1248, -0.2646, -0.6171,  ...,  2.4624, -0.0698, -0.3528],\n        [-0.1248, -0.2646,  2.0618,  ..., -0.3254, -0.0698, -0.3528],\n        [ 6.9879, -0.2646, -0.6171,  ..., -0.3254, -0.0698, -0.3528]],\n       device='cuda:0')"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "early_stopping = True\n",
    "n_epochs = 25_000\n",
    "n_plot_intervals = 1\n",
    "lyapunov_penalty = True\n",
    "perfect_interventions = True\n",
    "n_genes = samples.shape[1]\n",
    "\n",
    "GPU_DEVICE = 0\n",
    "device = torch.device(f\"cuda:{GPU_DEVICE}\")\n",
    "gt_interv = gt_interv.to(device)\n",
    "\n",
    "for scale_l1 in [0]:\n",
    "    for scale_spectral_loss in [10]:\n",
    "        for scale_lyapunov in [1, 10]:\n",
    "            print(f\"Scale Lyapunov: {scale_lyapunov}\")\n",
    "            print(f\"Scale spectral loss: {scale_spectral_loss}\")\n",
    "            model = BICYCLE(\n",
    "                lr,\n",
    "                gt_interv,\n",
    "                n_genes,\n",
    "                lyapunov_penalty=lyapunov_penalty,\n",
    "                perfect_interventions=perfect_interventions,\n",
    "                rank_w_cov_factor=2,\n",
    "                inits=None,\n",
    "                optimizer=\"adam\",\n",
    "                device=device,\n",
    "                normalise=False,\n",
    "                scale_l1=scale_l1,\n",
    "                scale_lyapunov=scale_lyapunov,\n",
    "                scale_spectral_loss=scale_spectral_loss,\n",
    "                early_stopping=True,\n",
    "                early_stopping_min_delta=0.02,\n",
    "                early_stopping_patience=400,\n",
    "                early_stopping_p_mode=True,\n",
    "            )\n",
    "            model.to(device)\n",
    "\n",
    "            dlogger = DictLogger()\n",
    "            loggers = [dlogger]\n",
    "\n",
    "            from pytorch_lightning.callbacks import RichProgressBar\n",
    "\n",
    "            assert str(device).startswith(\"cuda\")\n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=n_epochs,\n",
    "                accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                logger=loggers,\n",
    "                log_every_n_steps=n_plot_intervals,\n",
    "                enable_model_summary=True,\n",
    "                enable_progress_bar=True,\n",
    "                enable_checkpointing=False,\n",
    "                check_val_every_n_epoch=10,\n",
    "                devices=[GPU_DEVICE] if str(device).startswith(\"cuda\") else 1,\n",
    "                num_sanity_val_steps=0,\n",
    "                callbacks=[RichProgressBar()],\n",
    "            )\n",
    "\n",
    "            # try:\n",
    "            trainer.fit(model, train_loader)\n",
    "\n",
    "            # Plot training curve\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "            df_plot = pd.DataFrame(\n",
    "                {\n",
    "                    \"train_loss\": trainer.logger.history[\"train_loss\"].reset_index(\n",
    "                        drop=True\n",
    "                    ),\n",
    "                    \"val_loss\": trainer.logger.history[\"val_loss\"].reset_index(\n",
    "                        drop=True\n",
    "                    ),\n",
    "                },\n",
    "            ).reset_index(drop=True)\n",
    "            ax[0].scatter(\n",
    "                range(len(df_plot)), df_plot[\"train_loss\"], label=\"train_loss\"\n",
    "            )\n",
    "            ax[1].scatter(range(len(df_plot)), df_plot[\"val_loss\"], label=\"val_loss\")\n",
    "            ax[0].grid(True)\n",
    "            ax[1].grid(True)\n",
    "            plt.show()\n",
    "\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "            sns.heatmap(\n",
    "                model.beta.detach().cpu().numpy(),\n",
    "                center=0,\n",
    "                cmap=\"vlag\",\n",
    "                annot=True,\n",
    "                fmt=\".2f\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e43ba5",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(trainer.logger.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
